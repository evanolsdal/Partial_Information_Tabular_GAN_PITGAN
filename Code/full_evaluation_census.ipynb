{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Models to be used\n",
    "from model.model_init import PITGAN\n",
    "from data_processing.data_transformer import DataTransformer\n",
    "\n",
    "# Data loading functions\n",
    "from data_processing.basic_synthetic_dataset import generate_basic_2D\n",
    "\n",
    "# Plot functions\n",
    "from visualizations.scatter_plots import plot_2D_data, plot_priv_utility\n",
    "from visualizations.training_loss_plots import plot_losses\n",
    "\n",
    "# Evaluation functinos\n",
    "from evaluation.evaluation_procedure import evaluate_full, evaluate\n",
    "from evaluation.utility import compute_ROC, compute_CIO, compute_CIO_folds, compute_pMSE\n",
    "\n",
    "# Additional functions\n",
    "from model.model_helpers import get_latent_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the full streamlined evaluation procedure for any data. \n",
    "\n",
    "It follows the following steps\n",
    "1. It starts by loading in the data\n",
    "2. Then it fits a transformer to this data which is adequate\n",
    "3. Then full evaluation procedure is run over various latent dimensions\n",
    "4. Then these evaluation outputs are used to plot the privacy-utility graph\n",
    "5. Finally some of these optimal paramters from the evaluation are used to gain further insight into the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load Data\n",
    "First the data is loaded in the data from whatever source. In this example the basic synthetic data example is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is load in a subset of ACS census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARST</th>\n",
       "      <th>RACE</th>\n",
       "      <th>CITIZEN</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>HEALTHCOV</th>\n",
       "      <th>EMPSTAT</th>\n",
       "      <th>POVERTY</th>\n",
       "      <th>INCTOT</th>\n",
       "      <th>FAMSIZE</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>811132</th>\n",
       "      <td>Midwest</td>\n",
       "      <td>Female</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Multi</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High_School</td>\n",
       "      <td>Pub_Cov</td>\n",
       "      <td>Not_in_LaborF</td>\n",
       "      <td>Below</td>\n",
       "      <td>780</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265911</th>\n",
       "      <td>West</td>\n",
       "      <td>Female</td>\n",
       "      <td>Separated</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High_School</td>\n",
       "      <td>Pub_Cov</td>\n",
       "      <td>Not_in_LaborF</td>\n",
       "      <td>Below</td>\n",
       "      <td>24000</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81939</th>\n",
       "      <td>West</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High_School</td>\n",
       "      <td>Priv_Cov</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Above</td>\n",
       "      <td>62200</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715948</th>\n",
       "      <td>Midwest</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High_School</td>\n",
       "      <td>Priv_Cov</td>\n",
       "      <td>Not_in_LaborF</td>\n",
       "      <td>Above</td>\n",
       "      <td>3500</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585979</th>\n",
       "      <td>South</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Priv_Cov</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Above</td>\n",
       "      <td>486000</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          REGION     SEX      MARST   RACE CITIZEN         EDUC HEALTHCOV  \\\n",
       "811132   Midwest  Female  Separated  Multi     Yes  High_School   Pub_Cov   \n",
       "2265911     West  Female  Separated  White     Yes  High_School   Pub_Cov   \n",
       "81939       West  Female    Married  White     Yes  High_School  Priv_Cov   \n",
       "1715948  Midwest  Female     Single  White     Yes  High_School  Priv_Cov   \n",
       "585979     South  Female    Married  Asian     Yes      Masters  Priv_Cov   \n",
       "\n",
       "               EMPSTAT POVERTY  INCTOT  FAMSIZE  AGE  \n",
       "811132   Not_in_LaborF   Below     780        1   61  \n",
       "2265911  Not_in_LaborF   Below   24000        1   64  \n",
       "81939         Employed   Above   62200        3   54  \n",
       "1715948  Not_in_LaborF   Above    3500        3   22  \n",
       "585979        Employed   Above  486000        3   56  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the census data\n",
    "X_train = pd.read_csv('C:/Users/olsda/OneDrive/Documents/NU classes/Year 4/MMSS Thesis/PITGAN Implenetation/Data/usa_00001/census_clean_2019.csv', index_col=False)\n",
    "\n",
    "# Sample only a certain portion\n",
    "X_train = X_train.sample(n=10000)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Fit Transformer\n",
    "\n",
    "This section fits the data transformer to the distribution. This is an important step of the process as the restructured representation can greatly impact the performace of the model. \n",
    "\n",
    "It is suggested to pick a representation which contains as few modes, or the most relevant modes, for the continuous variables as possible. This will both reduce the dimensionality of the feature space the generative model is trained on, as well as avoid unnecessarily complicated latice spaces that may either be difficult for the autoencoder to learn, or make the encoded space less useful later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 8, 10]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the transformer\n",
    "transformer = DataTransformer()\n",
    "\n",
    "# Specify which columns are discrete, important for both the transformer and functions later on\n",
    "discrete_columns = ['REGION','SEX','MARST','RACE','CITIZEN','EDUC','HEALTHCOV','EMPSTAT','POVERTY']\n",
    "\n",
    "# Train the transformer\n",
    "transformer.fit(X_train, discrete_columns)\n",
    "\n",
    "# Get the dimensionality of the modes, repeat fitting until a sufficiently low numer of modes are found\n",
    "D_list, C_list = transformer.get_relevant_dimensions()\n",
    "\n",
    "C_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Run Evaluation\n",
    "\n",
    "This is the longest step, both to set up and to run. It consists of two steps, first setting up all of the parameters needed for the full evaluation procedure, then running the actual procedure.\n",
    "\n",
    "The first part is crucial for successful training. While grid search is employed in the evaluation procedure it, since this procedure is run for a number of different latent dimensions, the training time compounds the more parameters are added. It is recommended to run a handful of smaller scale tests to hone in on which parameter ranges would likely be the most appropriate. The individual parameter choices are explained in more detail below.\n",
    "\n",
    "The actual evaluation portion this is the part that will take the longest to run, so it is recommended to run on GPU supported processing for accelerated network training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First take a look at the different options for the latent dimensions. The function latent_dims takes as input the total number of categories over all categorical variables, as well as the total number of modes across all continuous variables, and then outputs a table with the latent dimension size, the states on the lattice covered by this dimeniosn, and the number of states remaining.\n",
    "\n",
    "This function gives you an overall sense of how effective the different latent dimensions sizes may be, as well as the higher dimension size before identity mapping becomes possible. It is recommended to only run the evaluation on only the dimension lister here, or potentially less depending on prior knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+--------------------+\n",
      "|   Latent Dim |   States Covered |   States Remaining |\n",
      "+==============+==================+====================+\n",
      "|            0 |                0 |           15482880 |\n",
      "+--------------+------------------+--------------------+\n",
      "|            1 |                2 |           15482878 |\n",
      "+--------------+------------------+--------------------+\n",
      "|            2 |                4 |           15482874 |\n",
      "+--------------+------------------+--------------------+\n",
      "|            3 |                8 |           15482866 |\n",
      "+--------------+------------------+--------------------+\n",
      "|            4 |               16 |           15482850 |\n",
      "+--------------+------------------+--------------------+\n",
      "|            5 |               32 |           15482818 |\n",
      "+--------------+------------------+--------------------+\n",
      "|            6 |               64 |           15482754 |\n",
      "+--------------+------------------+--------------------+\n",
      "|            7 |              128 |           15482626 |\n",
      "+--------------+------------------+--------------------+\n",
      "|            8 |              256 |           15482370 |\n",
      "+--------------+------------------+--------------------+\n",
      "|            9 |              512 |           15481858 |\n",
      "+--------------+------------------+--------------------+\n",
      "|           10 |             1024 |           15480834 |\n",
      "+--------------+------------------+--------------------+\n",
      "|           11 |             2048 |           15478786 |\n",
      "+--------------+------------------+--------------------+\n",
      "|           12 |             4096 |           15474690 |\n",
      "+--------------+------------------+--------------------+\n",
      "|           13 |             8192 |           15466498 |\n",
      "+--------------+------------------+--------------------+\n",
      "|           14 |            16384 |           15450114 |\n",
      "+--------------+------------------+--------------------+\n",
      "|           15 |            32768 |           15417346 |\n",
      "+--------------+------------------+--------------------+\n",
      "|           16 |            65536 |           15351810 |\n",
      "+--------------+------------------+--------------------+\n",
      "|           17 |           131072 |           15220738 |\n",
      "+--------------+------------------+--------------------+\n",
      "|           18 |           262144 |           14958594 |\n",
      "+--------------+------------------+--------------------+\n",
      "|           19 |           524288 |           14434306 |\n",
      "+--------------+------------------+--------------------+\n",
      "|           20 |          1048576 |           13385730 |\n",
      "+--------------+------------------+--------------------+\n",
      "|           21 |          2097152 |           11288578 |\n",
      "+--------------+------------------+--------------------+\n",
      "|           22 |          4194304 |            7094274 |\n",
      "+--------------+------------------+--------------------+\n",
      "|           23 |          8388608 |                  0 |\n",
      "+--------------+------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# Run latent_dims\n",
    "get_latent_dims(D_list, C_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the dimensions for evaluation\n",
    "latent_dims = [0,5,10,15,20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next portion specifies the size or complexity of the network, broken down into the size of the different network parts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dictionary for the model sizes\n",
    "hidden_dimensions = {\n",
    "    'dim_e': [256, 128, 64],\n",
    "    'dim_r': [64, 128, 256],\n",
    "    'dim_g': [512, 512, 512],\n",
    "    'dim_c': [512, 512, 512],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next portion specifies the overall parameters to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dictionary for the overall model parameters\n",
    "parameters = {\n",
    "    'alpha_sup': 5, # balances sup and unsup loss for generator \n",
    "    'alpha_grad': 3, # balances gradient pen in critic loss\n",
    "    'batch_size': 512,\n",
    "    'grad_step_critic': 0.001,\n",
    "    'grad_step_generator': 0.001,\n",
    "    'grad_step_autoencoding': 0.001,\n",
    "    'sigmoid_temp': 0.3,\n",
    "    'softmax_temp': 0.3,\n",
    "    'critic_steps': 5,\n",
    "    'scale_continuous': 2,\n",
    "    'scale_noise': 1,\n",
    "    'scale_discrete': 2,\n",
    "    'R': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediate testing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PITGAN(5, hidden_dimensions, parameters, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_auto = model.fit_autoencoder(X_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting Generative Training\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling Concatenate.call().\n\n\u001b[1m{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [512,20] vs. shape[1] = [272,5] [Op:ConcatV2] name: concat\u001b[0m\n\nArguments received by Concatenate.call():\n  • inputs=['tf.Tensor(shape=(512, 20), dtype=float32)', 'tf.Tensor(shape=(272, 5), dtype=float32)']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m losses_gen \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\olsda\\OneDrive\\Documents\\NU classes\\Year 4\\MMSS Thesis\\PITGAN Implenetation\\Code\\model\\model_init.py:410\u001b[0m, in \u001b[0;36mPITGAN.fit_generative\u001b[1;34m(self, X_data, epochs)\u001b[0m\n\u001b[0;32m    407\u001b[0m     critic_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(critic_iterator)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;66;03m# Run gradient step for the critic based on the new batch\u001b[39;00m\n\u001b[1;32m--> 410\u001b[0m unsupervised_critic_loss, gradient_penalty_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_critic_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcritic_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;66;03m# Add the losses to the epoch losses\u001b[39;00m\n\u001b[0;32m    413\u001b[0m epoch_unsupervised_critic_losses\u001b[38;5;241m.\u001b[39mappend(unsupervised_critic_loss)\n",
      "File \u001b[1;32mc:\\Users\\olsda\\OneDrive\\Documents\\NU classes\\Year 4\\MMSS Thesis\\PITGAN Implenetation\\Code\\model\\model_init.py:269\u001b[0m, in \u001b[0;36mPITGAN.train_critic_step\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# Use these as inputs to the generator, as well as some sampeled noise, where we apply regular softmax to the\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;66;03m# output of the generator to get the continuous range of probabilities\u001b[39;00m\n\u001b[0;32m    268\u001b[0m Z \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR))\n\u001b[1;32m--> 269\u001b[0m X_hat_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m X_hat \u001b[38;5;241m=\u001b[39m apply_regular_softmax(X_hat_logits, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD_list, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC_list)\n\u001b[0;32m    271\u001b[0m X_hat_unscaled \u001b[38;5;241m=\u001b[39m X_hat[:, :\u001b[38;5;241m-\u001b[39mc]\n",
      "File \u001b[1;32mc:\\Users\\olsda\\OneDrive\\Documents\\NU classes\\Year 4\\MMSS Thesis\\PITGAN Implenetation\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\olsda\\OneDrive\\Documents\\NU classes\\Year 4\\MMSS Thesis\\PITGAN Implenetation\\.venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling Concatenate.call().\n\n\u001b[1m{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [512,20] vs. shape[1] = [272,5] [Op:ConcatV2] name: concat\u001b[0m\n\nArguments received by Concatenate.call():\n  • inputs=['tf.Tensor(shape=(512, 20), dtype=float32)', 'tf.Tensor(shape=(272, 5), dtype=float32)']"
     ]
    }
   ],
   "source": [
    "losses_gen = model.fit_generative(X_train, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(losses_gen, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the sets of keys to be used for privacy evaluation\n",
    "key_sets = [['REGION','SEX'],['REGION','SEX','MARST','RACE']]\n",
    "\n",
    "# Specify the regressions to be sued for CIO evaluation\n",
    "regressions = {\n",
    "    'Income_Full': (['INCTOT'],['AGE','FAMSIZE'],['SEX','RACE','CITIZEN','EDUC'])\n",
    "}\n",
    "\n",
    "# Specify utility weights\n",
    "utility_weights = [0.33, 0.33, 0.33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate(X_train, model, transformer, discrete_columns, key_sets, regressions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue Full Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next portion specifies the training specific hyper parameters to be used in the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dict for the autoencoder hyperparameters\n",
    "hyper_params_sup = [0.001, 0.0005, 0.0001]\n",
    "\n",
    "# Initialize the dictionary for the generative model grid\n",
    "hyper_params_unsup = {\n",
    "    'grad_step_critic': [0.001, 0.0001],\n",
    "    'grad_step_generator': [0.001, 0.0001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dict for the autoencoder hyperparameters\n",
    "hyper_params_sup = [0.001, 0.0001]\n",
    "\n",
    "# Initialize the dictionary for the generative model grid\n",
    "hyper_params_unsup = {\n",
    "    'grad_step_critic': [0.001],\n",
    "    'grad_step_generator': [0.0001]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next portion specifies the number of ephods for the autoencoder and unsupervised trianing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify autoencoder epochs\n",
    "auto_epochs = 100\n",
    "\n",
    "# Specify unsupervised epochs\n",
    "gen_epochs = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify autoencoder epochs\n",
    "auto_epochs = 100\n",
    "\n",
    "# Specify unsupervised epochs\n",
    "gen_epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next section specifies the evaluation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the sets of keys to be used for privacy evaluation\n",
    "key_sets = [['Category']]\n",
    "\n",
    "# Specify the regressions to be sued for CIO evaluation\n",
    "regressions = {\n",
    "    'Dim_1': (['Dimension_1'],['Dimension_2'],['Category']),\n",
    "    'Dim_2': (['Dimension_2'],['Dimension_1'],['Category'])\n",
    "}\n",
    "\n",
    "# Specify utility weights\n",
    "utility_weights = [0.33, 0.33, 0.33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally run the actual evaluation procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\olsda\\OneDrive\\Documents\\NU classes\\Year 4\\MMSS Thesis\\PITGAN Implenetation\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:187: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "---Starting Autoencoder Training\n",
      "Epoch 0: Reconstruction Loss = 1.4386321306228638\n",
      "Epoch 1: Reconstruction Loss = 1.4371367692947388\n",
      "Epoch 2: Reconstruction Loss = 1.4355782270431519\n",
      "Epoch 3: Reconstruction Loss = 1.4340529441833496\n",
      "Epoch 4: Reconstruction Loss = 1.4325519800186157\n",
      "Epoch 5: Reconstruction Loss = 1.4310582876205444\n",
      "Epoch 6: Reconstruction Loss = 1.4295669794082642\n",
      "Epoch 7: Reconstruction Loss = 1.428078532218933\n",
      "Epoch 8: Reconstruction Loss = 1.4265891313552856\n",
      "Epoch 9: Reconstruction Loss = 1.4251489639282227\n",
      "Epoch 10: Reconstruction Loss = 1.423697829246521\n",
      "Epoch 11: Reconstruction Loss = 1.4222310781478882\n",
      "Epoch 12: Reconstruction Loss = 1.4208110570907593\n",
      "Epoch 13: Reconstruction Loss = 1.4193897247314453\n",
      "Epoch 14: Reconstruction Loss = 1.41799795627594\n",
      "Epoch 15: Reconstruction Loss = 1.4165658950805664\n",
      "Epoch 16: Reconstruction Loss = 1.415201187133789\n",
      "Epoch 17: Reconstruction Loss = 1.4138065576553345\n",
      "Epoch 18: Reconstruction Loss = 1.4124394655227661\n",
      "Epoch 19: Reconstruction Loss = 1.4111003875732422\n",
      "Epoch 20: Reconstruction Loss = 1.4097309112548828\n",
      "Epoch 21: Reconstruction Loss = 1.4083958864212036\n",
      "Epoch 22: Reconstruction Loss = 1.4070595502853394\n",
      "Epoch 23: Reconstruction Loss = 1.4057350158691406\n",
      "Epoch 24: Reconstruction Loss = 1.4044585227966309\n",
      "Epoch 25: Reconstruction Loss = 1.4031339883804321\n",
      "Epoch 26: Reconstruction Loss = 1.4018508195877075\n",
      "Epoch 27: Reconstruction Loss = 1.400570034980774\n",
      "Epoch 28: Reconstruction Loss = 1.3993192911148071\n",
      "Epoch 29: Reconstruction Loss = 1.3980317115783691\n",
      "Epoch 30: Reconstruction Loss = 1.3968027830123901\n",
      "Epoch 31: Reconstruction Loss = 1.3955392837524414\n",
      "Epoch 32: Reconstruction Loss = 1.394336223602295\n",
      "Epoch 33: Reconstruction Loss = 1.393107295036316\n",
      "Epoch 34: Reconstruction Loss = 1.3918792009353638\n",
      "Epoch 35: Reconstruction Loss = 1.3906971216201782\n",
      "Epoch 36: Reconstruction Loss = 1.3894850015640259\n",
      "Epoch 37: Reconstruction Loss = 1.3883252143859863\n",
      "Epoch 38: Reconstruction Loss = 1.3871368169784546\n",
      "Epoch 39: Reconstruction Loss = 1.3859726190567017\n",
      "Epoch 40: Reconstruction Loss = 1.3848189115524292\n",
      "Epoch 41: Reconstruction Loss = 1.3836727142333984\n",
      "Epoch 42: Reconstruction Loss = 1.3825222253799438\n",
      "Epoch 43: Reconstruction Loss = 1.3813942670822144\n",
      "Epoch 44: Reconstruction Loss = 1.3802696466445923\n",
      "Epoch 45: Reconstruction Loss = 1.3791581392288208\n",
      "Epoch 46: Reconstruction Loss = 1.3780651092529297\n",
      "Epoch 47: Reconstruction Loss = 1.3769587278366089\n",
      "Epoch 48: Reconstruction Loss = 1.375868797302246\n",
      "Epoch 49: Reconstruction Loss = 1.3747882843017578\n",
      "Epoch 50: Reconstruction Loss = 1.3737255334854126\n",
      "Epoch 51: Reconstruction Loss = 1.3726739883422852\n",
      "Epoch 52: Reconstruction Loss = 1.3716254234313965\n",
      "Epoch 53: Reconstruction Loss = 1.370565414428711\n",
      "Epoch 54: Reconstruction Loss = 1.3695186376571655\n",
      "Epoch 55: Reconstruction Loss = 1.368502140045166\n",
      "Epoch 56: Reconstruction Loss = 1.3674801588058472\n",
      "Epoch 57: Reconstruction Loss = 1.3664780855178833\n",
      "Epoch 58: Reconstruction Loss = 1.3654547929763794\n",
      "Epoch 59: Reconstruction Loss = 1.364456057548523\n",
      "Epoch 60: Reconstruction Loss = 1.3634830713272095\n",
      "Epoch 61: Reconstruction Loss = 1.3624887466430664\n",
      "Epoch 62: Reconstruction Loss = 1.3615150451660156\n",
      "Epoch 63: Reconstruction Loss = 1.3605436086654663\n",
      "Epoch 64: Reconstruction Loss = 1.3596020936965942\n",
      "Epoch 65: Reconstruction Loss = 1.3586463928222656\n",
      "Epoch 66: Reconstruction Loss = 1.357709527015686\n",
      "Epoch 67: Reconstruction Loss = 1.3567599058151245\n",
      "Epoch 68: Reconstruction Loss = 1.3558248281478882\n",
      "Epoch 69: Reconstruction Loss = 1.3549233675003052\n",
      "Epoch 70: Reconstruction Loss = 1.3539916276931763\n",
      "Epoch 71: Reconstruction Loss = 1.353084683418274\n",
      "Epoch 72: Reconstruction Loss = 1.3521957397460938\n",
      "Epoch 73: Reconstruction Loss = 1.3512903451919556\n",
      "Epoch 74: Reconstruction Loss = 1.3504066467285156\n",
      "Epoch 75: Reconstruction Loss = 1.3495298624038696\n",
      "Epoch 76: Reconstruction Loss = 1.3486605882644653\n",
      "Epoch 77: Reconstruction Loss = 1.3477940559387207\n",
      "Epoch 78: Reconstruction Loss = 1.3469390869140625\n",
      "Epoch 79: Reconstruction Loss = 1.346096396446228\n",
      "Epoch 80: Reconstruction Loss = 1.3452272415161133\n",
      "Epoch 81: Reconstruction Loss = 1.3443979024887085\n",
      "Epoch 82: Reconstruction Loss = 1.3435779809951782\n",
      "Epoch 83: Reconstruction Loss = 1.3427454233169556\n",
      "Epoch 84: Reconstruction Loss = 1.3419197797775269\n",
      "Epoch 85: Reconstruction Loss = 1.3411102294921875\n",
      "Epoch 86: Reconstruction Loss = 1.3403081893920898\n",
      "Epoch 87: Reconstruction Loss = 1.339511752128601\n",
      "Epoch 88: Reconstruction Loss = 1.3387107849121094\n",
      "Epoch 89: Reconstruction Loss = 1.3379207849502563\n",
      "Epoch 90: Reconstruction Loss = 1.3371329307556152\n",
      "Epoch 91: Reconstruction Loss = 1.3363670110702515\n",
      "Epoch 92: Reconstruction Loss = 1.3355997800827026\n",
      "Epoch 93: Reconstruction Loss = 1.3348383903503418\n",
      "Epoch 94: Reconstruction Loss = 1.3340997695922852\n",
      "Epoch 95: Reconstruction Loss = 1.333335280418396\n",
      "Epoch 96: Reconstruction Loss = 1.3325737714767456\n",
      "Epoch 97: Reconstruction Loss = 1.3318538665771484\n",
      "Epoch 98: Reconstruction Loss = 1.3311134576797485\n",
      "Epoch 99: Reconstruction Loss = 1.3303812742233276\n",
      "---Finished Autoencoder Training\n",
      "---Starting Generative Training\n",
      "Epoch 0: Supervised Loss = nan Unsupervised Loss G = 0.28677898645401 Unsupervised Loss C = 0.6646574139595032 Gradient Penalty = 0.09219887852668762\n",
      "Epoch 1: Supervised Loss = nan Unsupervised Loss G = 0.0179530568420887 Unsupervised Loss C = 1.3970614671707153 Gradient Penalty = 0.05386725813150406\n",
      "Epoch 2: Supervised Loss = nan Unsupervised Loss G = -0.007704516407102346 Unsupervised Loss C = 1.7001093626022339 Gradient Penalty = 0.058098625391721725\n",
      "Epoch 3: Supervised Loss = nan Unsupervised Loss G = -0.06620023399591446 Unsupervised Loss C = 1.804497241973877 Gradient Penalty = 0.06668863445520401\n",
      "Epoch 4: Supervised Loss = nan Unsupervised Loss G = -0.07328308373689651 Unsupervised Loss C = 1.8115686178207397 Gradient Penalty = 0.06102858483791351\n",
      "Epoch 5: Supervised Loss = nan Unsupervised Loss G = -0.08703126758337021 Unsupervised Loss C = 1.8289231061935425 Gradient Penalty = 0.06281668692827225\n",
      "Epoch 6: Supervised Loss = nan Unsupervised Loss G = -0.07555245608091354 Unsupervised Loss C = 1.8367841243743896 Gradient Penalty = 0.06247010454535484\n",
      "Epoch 7: Supervised Loss = nan Unsupervised Loss G = -0.06949736922979355 Unsupervised Loss C = 1.8416837453842163 Gradient Penalty = 0.06290506571531296\n",
      "Epoch 8: Supervised Loss = nan Unsupervised Loss G = -0.04663483425974846 Unsupervised Loss C = 1.8408026695251465 Gradient Penalty = 0.06290699541568756\n",
      "Epoch 9: Supervised Loss = nan Unsupervised Loss G = -0.024399591609835625 Unsupervised Loss C = 1.8376227617263794 Gradient Penalty = 0.06303080171346664\n",
      "Epoch 10: Supervised Loss = nan Unsupervised Loss G = -0.012373200617730618 Unsupervised Loss C = 1.8333667516708374 Gradient Penalty = 0.06306874752044678\n",
      "Epoch 11: Supervised Loss = nan Unsupervised Loss G = -0.0003699498774949461 Unsupervised Loss C = 1.8279271125793457 Gradient Penalty = 0.06248502805829048\n",
      "Epoch 12: Supervised Loss = nan Unsupervised Loss G = 0.01637444831430912 Unsupervised Loss C = 1.8198940753936768 Gradient Penalty = 0.06222822144627571\n",
      "Epoch 13: Supervised Loss = nan Unsupervised Loss G = 0.023633254691958427 Unsupervised Loss C = 1.8078585863113403 Gradient Penalty = 0.06290161609649658\n",
      "Epoch 14: Supervised Loss = nan Unsupervised Loss G = 0.005204909015446901 Unsupervised Loss C = 1.797681450843811 Gradient Penalty = 0.062241051346063614\n",
      "Epoch 15: Supervised Loss = nan Unsupervised Loss G = -0.004936387296766043 Unsupervised Loss C = 1.7948023080825806 Gradient Penalty = 0.06199825927615166\n",
      "Epoch 16: Supervised Loss = nan Unsupervised Loss G = -0.027433788403868675 Unsupervised Loss C = 1.7884547710418701 Gradient Penalty = 0.061993274837732315\n",
      "Epoch 17: Supervised Loss = nan Unsupervised Loss G = -0.022050559520721436 Unsupervised Loss C = 1.7801052331924438 Gradient Penalty = 0.06146150827407837\n",
      "Epoch 18: Supervised Loss = nan Unsupervised Loss G = -0.01303450483828783 Unsupervised Loss C = 1.7666919231414795 Gradient Penalty = 0.061204422265291214\n",
      "Epoch 19: Supervised Loss = nan Unsupervised Loss G = -8.279030589619651e-05 Unsupervised Loss C = 1.755691647529602 Gradient Penalty = 0.05964754521846771\n",
      "Epoch 20: Supervised Loss = nan Unsupervised Loss G = 0.016819467768073082 Unsupervised Loss C = 1.7518651485443115 Gradient Penalty = 0.05994425714015961\n",
      "Epoch 21: Supervised Loss = nan Unsupervised Loss G = -0.005379354115575552 Unsupervised Loss C = 1.749203085899353 Gradient Penalty = 0.059986066073179245\n",
      "Epoch 22: Supervised Loss = nan Unsupervised Loss G = -0.005992824677377939 Unsupervised Loss C = 1.7382922172546387 Gradient Penalty = 0.0589054599404335\n",
      "Epoch 23: Supervised Loss = nan Unsupervised Loss G = -0.01068580150604248 Unsupervised Loss C = 1.7265973091125488 Gradient Penalty = 0.05940397456288338\n",
      "Epoch 24: Supervised Loss = nan Unsupervised Loss G = -0.0421694815158844 Unsupervised Loss C = 1.7118818759918213 Gradient Penalty = 0.05862132087349892\n",
      "Epoch 25: Supervised Loss = nan Unsupervised Loss G = -0.06751405447721481 Unsupervised Loss C = 1.7037811279296875 Gradient Penalty = 0.05770985409617424\n",
      "Epoch 26: Supervised Loss = nan Unsupervised Loss G = -0.04850878193974495 Unsupervised Loss C = 1.697878122329712 Gradient Penalty = 0.057106029242277145\n",
      "Epoch 27: Supervised Loss = nan Unsupervised Loss G = -0.01044541597366333 Unsupervised Loss C = 1.6832448244094849 Gradient Penalty = 0.05757616087794304\n",
      "Epoch 28: Supervised Loss = nan Unsupervised Loss G = 0.04566768929362297 Unsupervised Loss C = 1.6750582456588745 Gradient Penalty = 0.05673189088702202\n",
      "Epoch 29: Supervised Loss = nan Unsupervised Loss G = 0.05635519698262215 Unsupervised Loss C = 1.6716409921646118 Gradient Penalty = 0.05821553245186806\n",
      "Epoch 30: Supervised Loss = nan Unsupervised Loss G = 0.042928457260131836 Unsupervised Loss C = 1.6591932773590088 Gradient Penalty = 0.05741075053811073\n",
      "Epoch 31: Supervised Loss = nan Unsupervised Loss G = 0.025287598371505737 Unsupervised Loss C = 1.6469091176986694 Gradient Penalty = 0.05629756301641464\n",
      "Epoch 32: Supervised Loss = nan Unsupervised Loss G = -0.006474006455391645 Unsupervised Loss C = 1.6375688314437866 Gradient Penalty = 0.05688852816820145\n",
      "Epoch 33: Supervised Loss = nan Unsupervised Loss G = -0.029415344819426537 Unsupervised Loss C = 1.6336113214492798 Gradient Penalty = 0.05726903676986694\n",
      "Epoch 34: Supervised Loss = nan Unsupervised Loss G = -0.019289633259177208 Unsupervised Loss C = 1.6192833185195923 Gradient Penalty = 0.056652266532182693\n",
      "Epoch 35: Supervised Loss = nan Unsupervised Loss G = 0.024952834472060204 Unsupervised Loss C = 1.6165028810501099 Gradient Penalty = 0.05735791102051735\n",
      "Epoch 36: Supervised Loss = nan Unsupervised Loss G = 0.06293978542089462 Unsupervised Loss C = 1.6108458042144775 Gradient Penalty = 0.05719709023833275\n",
      "Epoch 37: Supervised Loss = nan Unsupervised Loss G = 0.045813385397195816 Unsupervised Loss C = 1.604975938796997 Gradient Penalty = 0.056788571178913116\n",
      "Epoch 38: Supervised Loss = nan Unsupervised Loss G = -0.014823582023382187 Unsupervised Loss C = 1.6032078266143799 Gradient Penalty = 0.05747448280453682\n",
      "Epoch 39: Supervised Loss = nan Unsupervised Loss G = -0.021454157307744026 Unsupervised Loss C = 1.595550298690796 Gradient Penalty = 0.05670125409960747\n",
      "Epoch 40: Supervised Loss = nan Unsupervised Loss G = -0.005069891922175884 Unsupervised Loss C = 1.58915376663208 Gradient Penalty = 0.05650690943002701\n",
      "Epoch 41: Supervised Loss = nan Unsupervised Loss G = 0.03077666275203228 Unsupervised Loss C = 1.583990216255188 Gradient Penalty = 0.05590338632464409\n",
      "Epoch 42: Supervised Loss = nan Unsupervised Loss G = 0.028496285900473595 Unsupervised Loss C = 1.5774646997451782 Gradient Penalty = 0.055897779762744904\n",
      "Epoch 43: Supervised Loss = nan Unsupervised Loss G = 0.01790751703083515 Unsupervised Loss C = 1.5729212760925293 Gradient Penalty = 0.05542485788464546\n",
      "Epoch 44: Supervised Loss = nan Unsupervised Loss G = -0.008168533444404602 Unsupervised Loss C = 1.5634207725524902 Gradient Penalty = 0.05448264628648758\n",
      "Epoch 45: Supervised Loss = nan Unsupervised Loss G = 0.011762996204197407 Unsupervised Loss C = 1.5585477352142334 Gradient Penalty = 0.05497181788086891\n",
      "Epoch 46: Supervised Loss = nan Unsupervised Loss G = 0.05348847433924675 Unsupervised Loss C = 1.5456589460372925 Gradient Penalty = 0.05399671941995621\n",
      "Epoch 47: Supervised Loss = nan Unsupervised Loss G = 0.050358060747385025 Unsupervised Loss C = 1.5391381978988647 Gradient Penalty = 0.05304477736353874\n",
      "Epoch 48: Supervised Loss = nan Unsupervised Loss G = 0.03564387187361717 Unsupervised Loss C = 1.5253537893295288 Gradient Penalty = 0.052818719297647476\n",
      "Epoch 49: Supervised Loss = nan Unsupervised Loss G = -0.01566694863140583 Unsupervised Loss C = 1.515684723854065 Gradient Penalty = 0.05181590095162392\n",
      "---Finished Generative Training\n",
      "---Starting Autoencoder Training\n",
      "Epoch 0: Reconstruction Loss = 1.434309482574463\n",
      "Epoch 1: Reconstruction Loss = 1.4173756837844849\n",
      "Epoch 2: Reconstruction Loss = 1.3993512392044067\n",
      "Epoch 3: Reconstruction Loss = 1.3808865547180176\n",
      "Epoch 4: Reconstruction Loss = 1.3571866750717163\n",
      "Epoch 5: Reconstruction Loss = 1.3332127332687378\n",
      "Epoch 6: Reconstruction Loss = 1.3101191520690918\n",
      "Epoch 7: Reconstruction Loss = 1.2855640649795532\n",
      "Epoch 8: Reconstruction Loss = 1.261408805847168\n",
      "Epoch 9: Reconstruction Loss = 1.2372441291809082\n",
      "Epoch 10: Reconstruction Loss = 1.2222261428833008\n",
      "Epoch 11: Reconstruction Loss = 1.2073849439620972\n",
      "Epoch 12: Reconstruction Loss = 1.186425805091858\n",
      "Epoch 13: Reconstruction Loss = 1.1738163232803345\n",
      "Epoch 14: Reconstruction Loss = 1.153099775314331\n",
      "Epoch 15: Reconstruction Loss = 1.130942702293396\n",
      "Epoch 16: Reconstruction Loss = 1.1101402044296265\n",
      "Epoch 17: Reconstruction Loss = 1.0958919525146484\n",
      "Epoch 18: Reconstruction Loss = 1.0765396356582642\n",
      "Epoch 19: Reconstruction Loss = 1.0560202598571777\n",
      "Epoch 20: Reconstruction Loss = 1.041256308555603\n",
      "Epoch 21: Reconstruction Loss = 1.021545171737671\n",
      "Epoch 22: Reconstruction Loss = 1.005771279335022\n",
      "Epoch 23: Reconstruction Loss = 0.9890143275260925\n",
      "Epoch 24: Reconstruction Loss = 0.972769558429718\n",
      "Epoch 25: Reconstruction Loss = 0.9639557003974915\n",
      "Epoch 26: Reconstruction Loss = 0.9501287341117859\n",
      "Epoch 27: Reconstruction Loss = 0.9385232329368591\n",
      "Epoch 28: Reconstruction Loss = 0.9375823140144348\n",
      "Epoch 29: Reconstruction Loss = 0.9257563948631287\n",
      "Epoch 30: Reconstruction Loss = 0.9156778454780579\n",
      "Epoch 31: Reconstruction Loss = 0.9487423896789551\n",
      "Epoch 32: Reconstruction Loss = 0.9426948428153992\n",
      "Epoch 33: Reconstruction Loss = 0.9216151237487793\n",
      "Epoch 34: Reconstruction Loss = 0.9166268706321716\n",
      "Epoch 35: Reconstruction Loss = 0.8923245072364807\n",
      "Epoch 36: Reconstruction Loss = 0.8879130482673645\n",
      "Epoch 37: Reconstruction Loss = 0.8722984790802002\n",
      "Epoch 38: Reconstruction Loss = 0.8665021061897278\n",
      "Epoch 39: Reconstruction Loss = 0.8608455061912537\n",
      "Epoch 40: Reconstruction Loss = 0.8579273223876953\n",
      "Epoch 41: Reconstruction Loss = 0.8704419732093811\n",
      "Epoch 42: Reconstruction Loss = 0.9237702488899231\n",
      "Epoch 43: Reconstruction Loss = 1.0311543941497803\n",
      "Epoch 44: Reconstruction Loss = 0.9252790808677673\n",
      "Epoch 45: Reconstruction Loss = 0.7771339416503906\n",
      "Epoch 46: Reconstruction Loss = 0.7407575249671936\n",
      "Epoch 47: Reconstruction Loss = 0.8485798239707947\n",
      "Epoch 48: Reconstruction Loss = 0.935326337814331\n",
      "Epoch 49: Reconstruction Loss = 0.7572970390319824\n",
      "Epoch 50: Reconstruction Loss = 0.6953770518302917\n",
      "Epoch 51: Reconstruction Loss = 0.68904048204422\n",
      "Epoch 52: Reconstruction Loss = 0.6814670562744141\n",
      "Epoch 53: Reconstruction Loss = 0.6806133389472961\n",
      "Epoch 54: Reconstruction Loss = 0.6698494553565979\n",
      "Epoch 55: Reconstruction Loss = 0.6638653874397278\n",
      "Epoch 56: Reconstruction Loss = 0.658801794052124\n",
      "Epoch 57: Reconstruction Loss = 0.655737578868866\n",
      "Epoch 58: Reconstruction Loss = 0.6529971957206726\n",
      "Epoch 59: Reconstruction Loss = 0.6503333449363708\n",
      "Epoch 60: Reconstruction Loss = 0.6488158106803894\n",
      "Epoch 61: Reconstruction Loss = 0.647686779499054\n",
      "Epoch 62: Reconstruction Loss = 0.6475579142570496\n",
      "Epoch 63: Reconstruction Loss = 0.6467825770378113\n",
      "Epoch 64: Reconstruction Loss = 0.6457705497741699\n",
      "Epoch 65: Reconstruction Loss = 0.6450573801994324\n",
      "Epoch 66: Reconstruction Loss = 0.645387589931488\n",
      "Epoch 67: Reconstruction Loss = 0.6450724005699158\n",
      "Epoch 68: Reconstruction Loss = 0.6448004841804504\n",
      "Epoch 69: Reconstruction Loss = 0.6438391208648682\n",
      "Epoch 70: Reconstruction Loss = 0.6443353295326233\n",
      "Epoch 71: Reconstruction Loss = 0.6441475749015808\n",
      "Epoch 72: Reconstruction Loss = 0.6440617442131042\n",
      "Epoch 73: Reconstruction Loss = 0.6475451588630676\n",
      "Epoch 74: Reconstruction Loss = 0.6437024474143982\n",
      "Epoch 75: Reconstruction Loss = 0.6428024768829346\n",
      "Epoch 76: Reconstruction Loss = 0.6468886733055115\n",
      "Epoch 77: Reconstruction Loss = 0.6434219479560852\n",
      "Epoch 78: Reconstruction Loss = 0.6474899649620056\n",
      "Epoch 79: Reconstruction Loss = 0.6432724595069885\n",
      "Epoch 80: Reconstruction Loss = 0.6431695818901062\n",
      "Epoch 81: Reconstruction Loss = 0.643119752407074\n",
      "Epoch 82: Reconstruction Loss = 0.6430327892303467\n",
      "Epoch 83: Reconstruction Loss = 0.6430034041404724\n",
      "Epoch 84: Reconstruction Loss = 0.6429521441459656\n",
      "Epoch 85: Reconstruction Loss = 0.6428520083427429\n",
      "Epoch 86: Reconstruction Loss = 0.6428136825561523\n",
      "Epoch 87: Reconstruction Loss = 0.6427898406982422\n",
      "Epoch 88: Reconstruction Loss = 0.6427421569824219\n",
      "Epoch 89: Reconstruction Loss = 0.6428073048591614\n",
      "Epoch 90: Reconstruction Loss = 0.642667829990387\n",
      "Epoch 91: Reconstruction Loss = 0.6426659226417542\n",
      "Epoch 92: Reconstruction Loss = 0.6426346898078918\n",
      "Epoch 93: Reconstruction Loss = 0.6426570415496826\n",
      "Epoch 94: Reconstruction Loss = 0.6425318121910095\n",
      "Epoch 95: Reconstruction Loss = 0.6417612433433533\n",
      "Epoch 96: Reconstruction Loss = 0.642479419708252\n",
      "Epoch 97: Reconstruction Loss = 0.6424883604049683\n",
      "Epoch 98: Reconstruction Loss = 0.6424784064292908\n",
      "Epoch 99: Reconstruction Loss = 0.6424005031585693\n",
      "---Finished Autoencoder Training\n",
      "---Starting Autoencoder Training\n",
      "Epoch 0: Reconstruction Loss = 1.4348177909851074\n",
      "Epoch 1: Reconstruction Loss = 1.4333162307739258\n",
      "Epoch 2: Reconstruction Loss = 1.430521845817566\n",
      "Epoch 3: Reconstruction Loss = 1.4296804666519165\n",
      "Epoch 4: Reconstruction Loss = 1.427207112312317\n",
      "Epoch 5: Reconstruction Loss = 1.423514723777771\n",
      "Epoch 6: Reconstruction Loss = 1.4213792085647583\n",
      "Epoch 7: Reconstruction Loss = 1.4187310934066772\n",
      "Epoch 8: Reconstruction Loss = 1.4183543920516968\n",
      "Epoch 9: Reconstruction Loss = 1.4146904945373535\n",
      "Epoch 10: Reconstruction Loss = 1.4120941162109375\n",
      "Epoch 11: Reconstruction Loss = 1.409122347831726\n",
      "Epoch 12: Reconstruction Loss = 1.4068289995193481\n",
      "Epoch 13: Reconstruction Loss = 1.4037946462631226\n",
      "Epoch 14: Reconstruction Loss = 1.4034072160720825\n",
      "Epoch 15: Reconstruction Loss = 1.3994728326797485\n",
      "Epoch 16: Reconstruction Loss = 1.3959509134292603\n",
      "Epoch 17: Reconstruction Loss = 1.3931173086166382\n",
      "Epoch 18: Reconstruction Loss = 1.3901203870773315\n",
      "Epoch 19: Reconstruction Loss = 1.387224555015564\n",
      "Epoch 20: Reconstruction Loss = 1.3834495544433594\n",
      "Epoch 21: Reconstruction Loss = 1.3802319765090942\n",
      "Epoch 22: Reconstruction Loss = 1.376883625984192\n",
      "Epoch 23: Reconstruction Loss = 1.3708242177963257\n",
      "Epoch 24: Reconstruction Loss = 1.3662656545639038\n",
      "Epoch 25: Reconstruction Loss = 1.3654569387435913\n",
      "Epoch 26: Reconstruction Loss = 1.361720085144043\n",
      "Epoch 27: Reconstruction Loss = 1.3562182188034058\n",
      "Epoch 28: Reconstruction Loss = 1.349736213684082\n",
      "Epoch 29: Reconstruction Loss = 1.3436561822891235\n",
      "Epoch 30: Reconstruction Loss = 1.343403935432434\n",
      "Epoch 31: Reconstruction Loss = 1.3351192474365234\n",
      "Epoch 32: Reconstruction Loss = 1.330434799194336\n",
      "Epoch 33: Reconstruction Loss = 1.3252863883972168\n",
      "Epoch 34: Reconstruction Loss = 1.323491096496582\n",
      "Epoch 35: Reconstruction Loss = 1.316481590270996\n",
      "Epoch 36: Reconstruction Loss = 1.3086663484573364\n",
      "Epoch 37: Reconstruction Loss = 1.3065658807754517\n",
      "Epoch 38: Reconstruction Loss = 1.3058217763900757\n",
      "Epoch 39: Reconstruction Loss = 1.2919164896011353\n",
      "Epoch 40: Reconstruction Loss = 1.2878621816635132\n",
      "Epoch 41: Reconstruction Loss = 1.278923749923706\n",
      "Epoch 42: Reconstruction Loss = 1.2749086618423462\n",
      "Epoch 43: Reconstruction Loss = 1.2737213373184204\n",
      "Epoch 44: Reconstruction Loss = 1.262459635734558\n",
      "Epoch 45: Reconstruction Loss = 1.2584199905395508\n",
      "Epoch 46: Reconstruction Loss = 1.2468217611312866\n",
      "Epoch 47: Reconstruction Loss = 1.2446377277374268\n",
      "Epoch 48: Reconstruction Loss = 1.236607313156128\n",
      "Epoch 49: Reconstruction Loss = 1.2268210649490356\n",
      "Epoch 50: Reconstruction Loss = 1.2211636304855347\n",
      "Epoch 51: Reconstruction Loss = 1.2237673997879028\n",
      "Epoch 52: Reconstruction Loss = 1.2142707109451294\n",
      "Epoch 53: Reconstruction Loss = 1.201562523841858\n",
      "Epoch 54: Reconstruction Loss = 1.2033336162567139\n",
      "Epoch 55: Reconstruction Loss = 1.1847959756851196\n",
      "Epoch 56: Reconstruction Loss = 1.1881681680679321\n",
      "Epoch 57: Reconstruction Loss = 1.1871895790100098\n",
      "Epoch 58: Reconstruction Loss = 1.1805564165115356\n",
      "Epoch 59: Reconstruction Loss = 1.1760406494140625\n",
      "Epoch 60: Reconstruction Loss = 1.1698037385940552\n",
      "Epoch 61: Reconstruction Loss = 1.162919044494629\n",
      "Epoch 62: Reconstruction Loss = 1.1595035791397095\n",
      "Epoch 63: Reconstruction Loss = 1.154202938079834\n",
      "Epoch 64: Reconstruction Loss = 1.1487799882888794\n",
      "Epoch 65: Reconstruction Loss = 1.1460938453674316\n",
      "Epoch 66: Reconstruction Loss = 1.1411019563674927\n",
      "Epoch 67: Reconstruction Loss = 1.1377267837524414\n",
      "Epoch 68: Reconstruction Loss = 1.1321967840194702\n",
      "Epoch 69: Reconstruction Loss = 1.1339730024337769\n",
      "Epoch 70: Reconstruction Loss = 1.1257996559143066\n",
      "Epoch 71: Reconstruction Loss = 1.1310032606124878\n",
      "Epoch 72: Reconstruction Loss = 1.1289187669754028\n",
      "Epoch 73: Reconstruction Loss = 1.1174778938293457\n",
      "Epoch 74: Reconstruction Loss = 1.1221569776535034\n",
      "Epoch 75: Reconstruction Loss = 1.1119637489318848\n",
      "Epoch 76: Reconstruction Loss = 1.1095384359359741\n",
      "Epoch 77: Reconstruction Loss = 1.109986662864685\n",
      "Epoch 78: Reconstruction Loss = 1.1089129447937012\n",
      "Epoch 79: Reconstruction Loss = 1.1073719263076782\n",
      "Epoch 80: Reconstruction Loss = 1.10068941116333\n",
      "Epoch 81: Reconstruction Loss = 1.0964922904968262\n",
      "Epoch 82: Reconstruction Loss = 1.1032909154891968\n",
      "Epoch 83: Reconstruction Loss = 1.096762776374817\n",
      "Epoch 84: Reconstruction Loss = 1.096017837524414\n",
      "Epoch 85: Reconstruction Loss = 1.0910454988479614\n",
      "Epoch 86: Reconstruction Loss = 1.08968985080719\n",
      "Epoch 87: Reconstruction Loss = 1.0847545862197876\n",
      "Epoch 88: Reconstruction Loss = 1.0827957391738892\n",
      "Epoch 89: Reconstruction Loss = 1.0814167261123657\n",
      "Epoch 90: Reconstruction Loss = 1.0802103281021118\n",
      "Epoch 91: Reconstruction Loss = 1.0789812803268433\n",
      "Epoch 92: Reconstruction Loss = 1.0731035470962524\n",
      "Epoch 93: Reconstruction Loss = 1.078110933303833\n",
      "Epoch 94: Reconstruction Loss = 1.0749188661575317\n",
      "Epoch 95: Reconstruction Loss = 1.067729115486145\n",
      "Epoch 96: Reconstruction Loss = 1.066534399986267\n",
      "Epoch 97: Reconstruction Loss = 1.0672248601913452\n",
      "Epoch 98: Reconstruction Loss = 1.0667448043823242\n",
      "Epoch 99: Reconstruction Loss = 1.0708459615707397\n",
      "---Finished Autoencoder Training\n",
      "---Starting Autoencoder Training\n",
      "Epoch 0: Reconstruction Loss = 1.441657543182373\n",
      "Epoch 1: Reconstruction Loss = 1.4322022199630737\n",
      "Epoch 2: Reconstruction Loss = 1.4238446950912476\n",
      "Epoch 3: Reconstruction Loss = 1.41426420211792\n",
      "Epoch 4: Reconstruction Loss = 1.4024285078048706\n",
      "Epoch 5: Reconstruction Loss = 1.3898664712905884\n",
      "Epoch 6: Reconstruction Loss = 1.3729561567306519\n",
      "Epoch 7: Reconstruction Loss = 1.3518786430358887\n",
      "Epoch 8: Reconstruction Loss = 1.3272795677185059\n",
      "Epoch 9: Reconstruction Loss = 1.296494483947754\n",
      "Epoch 10: Reconstruction Loss = 1.2740154266357422\n",
      "Epoch 11: Reconstruction Loss = 1.2455888986587524\n",
      "Epoch 12: Reconstruction Loss = 1.2299737930297852\n",
      "Epoch 13: Reconstruction Loss = 1.2084065675735474\n",
      "Epoch 14: Reconstruction Loss = 1.1989293098449707\n",
      "Epoch 15: Reconstruction Loss = 1.1890316009521484\n",
      "Epoch 16: Reconstruction Loss = 1.1681290864944458\n",
      "Epoch 17: Reconstruction Loss = 1.1492629051208496\n",
      "Epoch 18: Reconstruction Loss = 1.1320977210998535\n",
      "Epoch 19: Reconstruction Loss = 1.0994210243225098\n",
      "Epoch 20: Reconstruction Loss = 1.076402187347412\n",
      "Epoch 21: Reconstruction Loss = 1.052254557609558\n",
      "Epoch 22: Reconstruction Loss = 1.0273995399475098\n",
      "Epoch 23: Reconstruction Loss = 1.009940266609192\n",
      "Epoch 24: Reconstruction Loss = 0.9863618016242981\n",
      "Epoch 25: Reconstruction Loss = 0.9687630534172058\n",
      "Epoch 26: Reconstruction Loss = 0.9448080062866211\n",
      "Epoch 27: Reconstruction Loss = 0.9298350214958191\n",
      "Epoch 28: Reconstruction Loss = 0.9116232395172119\n",
      "Epoch 29: Reconstruction Loss = 0.8946254849433899\n",
      "Epoch 30: Reconstruction Loss = 0.8819549679756165\n",
      "Epoch 31: Reconstruction Loss = 0.8708977103233337\n",
      "Epoch 32: Reconstruction Loss = 0.8591830134391785\n",
      "Epoch 33: Reconstruction Loss = 0.8579617142677307\n",
      "Epoch 34: Reconstruction Loss = 0.8643653988838196\n",
      "Epoch 35: Reconstruction Loss = 0.8678574562072754\n",
      "Epoch 36: Reconstruction Loss = 0.8467898368835449\n",
      "Epoch 37: Reconstruction Loss = 0.829763650894165\n",
      "Epoch 38: Reconstruction Loss = 0.8168297410011292\n",
      "Epoch 39: Reconstruction Loss = 0.810030460357666\n",
      "Epoch 40: Reconstruction Loss = 0.8058850765228271\n",
      "Epoch 41: Reconstruction Loss = 0.8169956207275391\n",
      "Epoch 42: Reconstruction Loss = 0.8378572463989258\n",
      "Epoch 43: Reconstruction Loss = 0.8935074210166931\n",
      "Epoch 44: Reconstruction Loss = 1.0046690702438354\n",
      "Epoch 45: Reconstruction Loss = 0.9202346801757812\n",
      "Epoch 46: Reconstruction Loss = 0.8638855814933777\n",
      "Epoch 47: Reconstruction Loss = 0.8379359841346741\n",
      "Epoch 48: Reconstruction Loss = 0.8273088335990906\n",
      "Epoch 49: Reconstruction Loss = 0.8271021246910095\n",
      "Epoch 50: Reconstruction Loss = 0.8143685460090637\n",
      "Epoch 51: Reconstruction Loss = 0.7989284992218018\n",
      "Epoch 52: Reconstruction Loss = 0.7977278232574463\n",
      "Epoch 53: Reconstruction Loss = 0.80096435546875\n",
      "Epoch 54: Reconstruction Loss = 0.796616792678833\n",
      "Epoch 55: Reconstruction Loss = 0.7942204475402832\n",
      "Epoch 56: Reconstruction Loss = 0.7918389439582825\n",
      "Epoch 57: Reconstruction Loss = 0.7911479473114014\n",
      "Epoch 58: Reconstruction Loss = 0.790804922580719\n",
      "Epoch 59: Reconstruction Loss = 0.7904953956604004\n",
      "Epoch 60: Reconstruction Loss = 0.7898891568183899\n",
      "Epoch 61: Reconstruction Loss = 0.7916705012321472\n",
      "Epoch 62: Reconstruction Loss = 0.7885241508483887\n",
      "Epoch 63: Reconstruction Loss = 0.7882223725318909\n",
      "Epoch 64: Reconstruction Loss = 0.7880098223686218\n",
      "Epoch 65: Reconstruction Loss = 0.788987934589386\n",
      "Epoch 66: Reconstruction Loss = 0.7874675393104553\n",
      "Epoch 67: Reconstruction Loss = 0.787298858165741\n",
      "Epoch 68: Reconstruction Loss = 0.7871012091636658\n",
      "Epoch 69: Reconstruction Loss = 0.7897860407829285\n",
      "Epoch 70: Reconstruction Loss = 0.7868743538856506\n",
      "Epoch 71: Reconstruction Loss = 0.7867267727851868\n",
      "Epoch 72: Reconstruction Loss = 0.7894620299339294\n",
      "Epoch 73: Reconstruction Loss = 0.793408215045929\n",
      "Epoch 74: Reconstruction Loss = 0.7878046631813049\n",
      "Epoch 75: Reconstruction Loss = 0.7864530682563782\n",
      "Epoch 76: Reconstruction Loss = 0.7918582558631897\n",
      "Epoch 77: Reconstruction Loss = 0.7877474427223206\n",
      "Epoch 78: Reconstruction Loss = 0.7903680205345154\n",
      "Epoch 79: Reconstruction Loss = 0.7878084182739258\n",
      "Epoch 80: Reconstruction Loss = 0.7862241864204407\n",
      "Epoch 81: Reconstruction Loss = 0.7861612439155579\n",
      "Epoch 82: Reconstruction Loss = 0.7861943244934082\n",
      "Epoch 83: Reconstruction Loss = 0.7902849316596985\n",
      "Epoch 84: Reconstruction Loss = 0.790232241153717\n",
      "Epoch 85: Reconstruction Loss = 0.7901414036750793\n",
      "Epoch 86: Reconstruction Loss = 0.7888429760932922\n",
      "Epoch 87: Reconstruction Loss = 0.7943511009216309\n",
      "Epoch 88: Reconstruction Loss = 0.7942526936531067\n",
      "Epoch 89: Reconstruction Loss = 0.7955515384674072\n",
      "Epoch 90: Reconstruction Loss = 0.8120803833007812\n",
      "Epoch 91: Reconstruction Loss = 0.8195115923881531\n",
      "Epoch 92: Reconstruction Loss = 0.8667677044868469\n",
      "Epoch 93: Reconstruction Loss = 0.9444634318351746\n",
      "Epoch 94: Reconstruction Loss = 1.0170948505401611\n",
      "Epoch 95: Reconstruction Loss = 0.9955319762229919\n",
      "Epoch 96: Reconstruction Loss = 0.9089803695678711\n",
      "Epoch 97: Reconstruction Loss = 0.8875884413719177\n",
      "Epoch 98: Reconstruction Loss = 0.8799476623535156\n",
      "Epoch 99: Reconstruction Loss = 0.8726924061775208\n",
      "---Finished Autoencoder Training\n",
      "---Starting Generative Training\n",
      "Epoch 0: Supervised Loss = 4.151498317718506 Unsupervised Loss G = -0.03573049232363701 Unsupervised Loss C = 0.6927736401557922 Gradient Penalty = 0.1047433540225029\n",
      "Epoch 1: Supervised Loss = 4.116383075714111 Unsupervised Loss G = 0.04800410941243172 Unsupervised Loss C = 1.603124976158142 Gradient Penalty = 0.0765010192990303\n",
      "Epoch 2: Supervised Loss = 4.045179843902588 Unsupervised Loss G = 0.0184769406914711 Unsupervised Loss C = 1.776172161102295 Gradient Penalty = 0.06763429939746857\n",
      "Epoch 3: Supervised Loss = 4.055194854736328 Unsupervised Loss G = 0.0007035427843220532 Unsupervised Loss C = 1.8470051288604736 Gradient Penalty = 0.06704127788543701\n",
      "Epoch 4: Supervised Loss = 3.994710683822632 Unsupervised Loss G = 0.008496561087667942 Unsupervised Loss C = 1.8612899780273438 Gradient Penalty = 0.06344472616910934\n",
      "Epoch 5: Supervised Loss = 3.9203710556030273 Unsupervised Loss G = 0.0034218106884509325 Unsupervised Loss C = 1.8703385591506958 Gradient Penalty = 0.06467625498771667\n",
      "Epoch 6: Supervised Loss = 3.8172671794891357 Unsupervised Loss G = 0.009992516599595547 Unsupervised Loss C = 1.8671720027923584 Gradient Penalty = 0.06297914683818817\n",
      "Epoch 7: Supervised Loss = 3.715535879135132 Unsupervised Loss G = 0.027699431404471397 Unsupervised Loss C = 1.8661689758300781 Gradient Penalty = 0.06337016075849533\n",
      "Epoch 8: Supervised Loss = 3.6341989040374756 Unsupervised Loss G = 0.046923261135816574 Unsupervised Loss C = 1.86655855178833 Gradient Penalty = 0.06387579441070557\n",
      "Epoch 9: Supervised Loss = 3.6019153594970703 Unsupervised Loss G = 0.055013611912727356 Unsupervised Loss C = 1.858143925666809 Gradient Penalty = 0.06277550756931305\n",
      "Epoch 10: Supervised Loss = 3.4423038959503174 Unsupervised Loss G = 0.045744698494672775 Unsupervised Loss C = 1.8507020473480225 Gradient Penalty = 0.06231938675045967\n",
      "Epoch 11: Supervised Loss = 3.4560766220092773 Unsupervised Loss G = 0.03877869248390198 Unsupervised Loss C = 1.8493125438690186 Gradient Penalty = 0.0630263015627861\n",
      "Epoch 12: Supervised Loss = 3.2251532077789307 Unsupervised Loss G = 0.02053835615515709 Unsupervised Loss C = 1.8415024280548096 Gradient Penalty = 0.06227372586727142\n",
      "Epoch 13: Supervised Loss = 3.1806223392486572 Unsupervised Loss G = 0.013086321763694286 Unsupervised Loss C = 1.8342530727386475 Gradient Penalty = 0.061916567385196686\n",
      "Epoch 14: Supervised Loss = 3.1021347045898438 Unsupervised Loss G = -0.0021815120708197355 Unsupervised Loss C = 1.8280017375946045 Gradient Penalty = 0.06177150458097458\n",
      "Epoch 15: Supervised Loss = 2.814639091491699 Unsupervised Loss G = -0.015247236005961895 Unsupervised Loss C = 1.8222661018371582 Gradient Penalty = 0.061622362583875656\n",
      "Epoch 16: Supervised Loss = 2.721604585647583 Unsupervised Loss G = -0.019853832200169563 Unsupervised Loss C = 1.8132760524749756 Gradient Penalty = 0.06114429980516434\n",
      "Epoch 17: Supervised Loss = 2.695688247680664 Unsupervised Loss G = -0.04011555388569832 Unsupervised Loss C = 1.8103787899017334 Gradient Penalty = 0.06170116364955902\n",
      "Epoch 18: Supervised Loss = 2.553450584411621 Unsupervised Loss G = -0.06665033102035522 Unsupervised Loss C = 1.8066942691802979 Gradient Penalty = 0.06157279387116432\n",
      "Epoch 19: Supervised Loss = 2.3110668659210205 Unsupervised Loss G = -0.07281144708395004 Unsupervised Loss C = 1.8008419275283813 Gradient Penalty = 0.06100430339574814\n",
      "Epoch 20: Supervised Loss = 1.9410943984985352 Unsupervised Loss G = -0.10711828619241714 Unsupervised Loss C = 1.7925845384597778 Gradient Penalty = 0.06019033491611481\n",
      "Epoch 21: Supervised Loss = 1.9197877645492554 Unsupervised Loss G = -0.12579573690891266 Unsupervised Loss C = 1.7918944358825684 Gradient Penalty = 0.06180628016591072\n",
      "Epoch 22: Supervised Loss = 1.6822375059127808 Unsupervised Loss G = -0.11457029730081558 Unsupervised Loss C = 1.7799218893051147 Gradient Penalty = 0.06036502495408058\n",
      "Epoch 23: Supervised Loss = 1.4009151458740234 Unsupervised Loss G = -0.10846664756536484 Unsupervised Loss C = 1.775141954421997 Gradient Penalty = 0.06006091460585594\n",
      "Epoch 24: Supervised Loss = 1.2506238222122192 Unsupervised Loss G = -0.10025867074728012 Unsupervised Loss C = 1.7689340114593506 Gradient Penalty = 0.05966008082032204\n",
      "Epoch 25: Supervised Loss = 1.1488150358200073 Unsupervised Loss G = -0.12397363781929016 Unsupervised Loss C = 1.7669347524642944 Gradient Penalty = 0.06088521331548691\n",
      "Epoch 26: Supervised Loss = 1.178078293800354 Unsupervised Loss G = -0.13305440545082092 Unsupervised Loss C = 1.7564055919647217 Gradient Penalty = 0.05899578332901001\n",
      "Epoch 27: Supervised Loss = 0.9706829190254211 Unsupervised Loss G = -0.1817295104265213 Unsupervised Loss C = 1.7473771572113037 Gradient Penalty = 0.06010695919394493\n",
      "Epoch 28: Supervised Loss = 0.8805424571037292 Unsupervised Loss G = -0.14189808070659637 Unsupervised Loss C = 1.7437479496002197 Gradient Penalty = 0.05967877805233002\n",
      "Epoch 29: Supervised Loss = 0.7609307169914246 Unsupervised Loss G = -0.15322616696357727 Unsupervised Loss C = 1.7312816381454468 Gradient Penalty = 0.05889245495200157\n",
      "Epoch 30: Supervised Loss = 0.6978586316108704 Unsupervised Loss G = -0.1735612154006958 Unsupervised Loss C = 1.7219548225402832 Gradient Penalty = 0.058563195168972015\n",
      "Epoch 31: Supervised Loss = 0.5640720725059509 Unsupervised Loss G = -0.15191341936588287 Unsupervised Loss C = 1.7093454599380493 Gradient Penalty = 0.05726815015077591\n",
      "Epoch 32: Supervised Loss = 0.6075859069824219 Unsupervised Loss G = -0.15517033636569977 Unsupervised Loss C = 1.7001057863235474 Gradient Penalty = 0.05745136737823486\n",
      "Epoch 33: Supervised Loss = 0.5219666957855225 Unsupervised Loss G = -0.15660123527050018 Unsupervised Loss C = 1.6847738027572632 Gradient Penalty = 0.05500095710158348\n",
      "Epoch 34: Supervised Loss = 0.4313267767429352 Unsupervised Loss G = -0.1854674369096756 Unsupervised Loss C = 1.6793442964553833 Gradient Penalty = 0.05667262524366379\n",
      "Epoch 35: Supervised Loss = 0.3833051025867462 Unsupervised Loss G = -0.17465274035930634 Unsupervised Loss C = 1.6640820503234863 Gradient Penalty = 0.054388634860515594\n",
      "Epoch 36: Supervised Loss = 0.3323858082294464 Unsupervised Loss G = -0.19433794915676117 Unsupervised Loss C = 1.6550768613815308 Gradient Penalty = 0.05546870082616806\n",
      "Epoch 37: Supervised Loss = 0.34224796295166016 Unsupervised Loss G = -0.17824895679950714 Unsupervised Loss C = 1.641013503074646 Gradient Penalty = 0.054848622530698776\n",
      "Epoch 38: Supervised Loss = 0.3545776903629303 Unsupervised Loss G = -0.17904584109783173 Unsupervised Loss C = 1.6297160387039185 Gradient Penalty = 0.053848620504140854\n",
      "Epoch 39: Supervised Loss = 0.2992359697818756 Unsupervised Loss G = -0.1581224650144577 Unsupervised Loss C = 1.618795394897461 Gradient Penalty = 0.05379704385995865\n",
      "Epoch 40: Supervised Loss = 0.20949618518352509 Unsupervised Loss G = -0.16901838779449463 Unsupervised Loss C = 1.6036797761917114 Gradient Penalty = 0.05243472754955292\n",
      "Epoch 41: Supervised Loss = 0.23279185593128204 Unsupervised Loss G = -0.172006294131279 Unsupervised Loss C = 1.5920149087905884 Gradient Penalty = 0.05198221281170845\n",
      "Epoch 42: Supervised Loss = 0.2473960667848587 Unsupervised Loss G = -0.18508708477020264 Unsupervised Loss C = 1.5747888088226318 Gradient Penalty = 0.05160003527998924\n",
      "Epoch 43: Supervised Loss = 0.20151443779468536 Unsupervised Loss G = -0.18762211501598358 Unsupervised Loss C = 1.5590846538543701 Gradient Penalty = 0.053332991898059845\n",
      "Epoch 44: Supervised Loss = 0.20469361543655396 Unsupervised Loss G = -0.14960168302059174 Unsupervised Loss C = 1.5359359979629517 Gradient Penalty = 0.04919479042291641\n",
      "Epoch 45: Supervised Loss = 0.22629046440124512 Unsupervised Loss G = -0.14894725382328033 Unsupervised Loss C = 1.5222258567810059 Gradient Penalty = 0.049451425671577454\n",
      "Epoch 46: Supervised Loss = 0.18834178149700165 Unsupervised Loss G = -0.1266135722398758 Unsupervised Loss C = 1.507061243057251 Gradient Penalty = 0.04890444129705429\n",
      "Epoch 47: Supervised Loss = 0.1641906499862671 Unsupervised Loss G = -0.1149088516831398 Unsupervised Loss C = 1.485813021659851 Gradient Penalty = 0.047276634722948074\n",
      "Epoch 48: Supervised Loss = 0.2079836130142212 Unsupervised Loss G = -0.12341739982366562 Unsupervised Loss C = 1.47190260887146 Gradient Penalty = 0.04744274541735649\n",
      "Epoch 49: Supervised Loss = 0.26329395174980164 Unsupervised Loss G = -0.10003437846899033 Unsupervised Loss C = 1.4491990804672241 Gradient Penalty = 0.04536866396665573\n",
      "---Finished Generative Training\n",
      "---Starting Autoencoder Training\n",
      "Epoch 0: Reconstruction Loss = 1.453061580657959\n",
      "Epoch 1: Reconstruction Loss = 1.4313958883285522\n",
      "Epoch 2: Reconstruction Loss = 1.4118643999099731\n",
      "Epoch 3: Reconstruction Loss = 1.3947309255599976\n",
      "Epoch 4: Reconstruction Loss = 1.3749676942825317\n",
      "Epoch 5: Reconstruction Loss = 1.3525499105453491\n",
      "Epoch 6: Reconstruction Loss = 1.3280969858169556\n",
      "Epoch 7: Reconstruction Loss = 1.295973300933838\n",
      "Epoch 8: Reconstruction Loss = 1.263464331626892\n",
      "Epoch 9: Reconstruction Loss = 1.2227476835250854\n",
      "Epoch 10: Reconstruction Loss = 1.1865886449813843\n",
      "Epoch 11: Reconstruction Loss = 1.1428495645523071\n",
      "Epoch 12: Reconstruction Loss = 1.0958328247070312\n",
      "Epoch 13: Reconstruction Loss = 1.0450119972229004\n",
      "Epoch 14: Reconstruction Loss = 0.9924007058143616\n",
      "Epoch 15: Reconstruction Loss = 0.9317166805267334\n",
      "Epoch 16: Reconstruction Loss = 0.8701754212379456\n",
      "Epoch 17: Reconstruction Loss = 0.811588704586029\n",
      "Epoch 18: Reconstruction Loss = 0.7594284415245056\n",
      "Epoch 19: Reconstruction Loss = 0.7150059342384338\n",
      "Epoch 20: Reconstruction Loss = 0.6758354306221008\n",
      "Epoch 21: Reconstruction Loss = 0.6479272246360779\n",
      "Epoch 22: Reconstruction Loss = 0.6226562857627869\n",
      "Epoch 23: Reconstruction Loss = 0.607396125793457\n",
      "Epoch 24: Reconstruction Loss = 0.5955273509025574\n",
      "Epoch 25: Reconstruction Loss = 0.5882146954536438\n",
      "Epoch 26: Reconstruction Loss = 0.5847836136817932\n",
      "Epoch 27: Reconstruction Loss = 0.5821549296379089\n",
      "Epoch 28: Reconstruction Loss = 0.579628586769104\n",
      "Epoch 29: Reconstruction Loss = 0.5781798958778381\n",
      "Epoch 30: Reconstruction Loss = 0.5765420794487\n",
      "Epoch 31: Reconstruction Loss = 0.575922429561615\n",
      "Epoch 32: Reconstruction Loss = 0.575756311416626\n",
      "Epoch 33: Reconstruction Loss = 0.5761279463768005\n",
      "Epoch 34: Reconstruction Loss = 0.5749444365501404\n",
      "Epoch 35: Reconstruction Loss = 0.5748552680015564\n",
      "Epoch 36: Reconstruction Loss = 0.5764743685722351\n",
      "Epoch 37: Reconstruction Loss = 0.5745200514793396\n",
      "Epoch 38: Reconstruction Loss = 0.5759546756744385\n",
      "Epoch 39: Reconstruction Loss = 0.5734390616416931\n",
      "Epoch 40: Reconstruction Loss = 0.5743064880371094\n",
      "Epoch 41: Reconstruction Loss = 0.5727249979972839\n",
      "Epoch 42: Reconstruction Loss = 0.5755038261413574\n",
      "Epoch 43: Reconstruction Loss = 0.5741198658943176\n",
      "Epoch 44: Reconstruction Loss = 0.5746447443962097\n",
      "Epoch 45: Reconstruction Loss = 0.5726889967918396\n",
      "Epoch 46: Reconstruction Loss = 0.5762031078338623\n",
      "Epoch 47: Reconstruction Loss = 0.5717343688011169\n",
      "Epoch 48: Reconstruction Loss = 0.5717964768409729\n",
      "Epoch 49: Reconstruction Loss = 0.5727565288543701\n",
      "Epoch 50: Reconstruction Loss = 0.5760700106620789\n",
      "Epoch 51: Reconstruction Loss = 0.5732201933860779\n",
      "Epoch 52: Reconstruction Loss = 0.5744268298149109\n",
      "Epoch 53: Reconstruction Loss = 0.573571503162384\n",
      "Epoch 54: Reconstruction Loss = 0.5725260376930237\n",
      "Epoch 55: Reconstruction Loss = 0.5734636783599854\n",
      "Epoch 56: Reconstruction Loss = 0.5737739205360413\n",
      "Epoch 57: Reconstruction Loss = 0.5735926628112793\n",
      "Epoch 58: Reconstruction Loss = 0.5734832286834717\n",
      "Epoch 59: Reconstruction Loss = 0.5732526183128357\n",
      "Epoch 60: Reconstruction Loss = 0.5724164247512817\n",
      "Epoch 61: Reconstruction Loss = 0.5731036067008972\n",
      "Epoch 62: Reconstruction Loss = 0.5732216835021973\n",
      "Epoch 63: Reconstruction Loss = 0.573201596736908\n",
      "Epoch 64: Reconstruction Loss = 0.5732318758964539\n",
      "Epoch 65: Reconstruction Loss = 0.5740194916725159\n",
      "Epoch 66: Reconstruction Loss = 0.5741639733314514\n",
      "Epoch 67: Reconstruction Loss = 0.5718767046928406\n",
      "Epoch 68: Reconstruction Loss = 0.57206791639328\n",
      "Epoch 69: Reconstruction Loss = 0.5729454159736633\n",
      "Epoch 70: Reconstruction Loss = 0.5729320645332336\n",
      "Epoch 71: Reconstruction Loss = 0.5737529397010803\n",
      "Epoch 72: Reconstruction Loss = 0.5727688670158386\n",
      "Epoch 73: Reconstruction Loss = 0.5727444291114807\n",
      "Epoch 74: Reconstruction Loss = 0.5718141198158264\n",
      "Epoch 75: Reconstruction Loss = 0.5736635327339172\n",
      "Epoch 76: Reconstruction Loss = 0.5738540291786194\n",
      "Epoch 77: Reconstruction Loss = 0.5721497535705566\n",
      "Epoch 78: Reconstruction Loss = 0.5739174485206604\n",
      "Epoch 79: Reconstruction Loss = 0.5738933086395264\n",
      "Epoch 80: Reconstruction Loss = 0.5739659667015076\n",
      "Epoch 81: Reconstruction Loss = 0.5736185908317566\n",
      "Epoch 82: Reconstruction Loss = 0.5736373066902161\n",
      "Epoch 83: Reconstruction Loss = 0.5736439228057861\n",
      "Epoch 84: Reconstruction Loss = 0.5716424584388733\n",
      "Epoch 85: Reconstruction Loss = 0.5735301971435547\n",
      "Epoch 86: Reconstruction Loss = 0.5737150311470032\n",
      "Epoch 87: Reconstruction Loss = 0.5716472268104553\n",
      "Epoch 88: Reconstruction Loss = 0.5735430717468262\n",
      "Epoch 89: Reconstruction Loss = 0.5729015469551086\n",
      "Epoch 90: Reconstruction Loss = 0.5740291476249695\n",
      "Epoch 91: Reconstruction Loss = 0.5707702040672302\n",
      "Epoch 92: Reconstruction Loss = 0.5714680552482605\n",
      "Epoch 93: Reconstruction Loss = 0.5734817981719971\n",
      "Epoch 94: Reconstruction Loss = 0.5726339817047119\n",
      "Epoch 95: Reconstruction Loss = 0.5714001059532166\n",
      "Epoch 96: Reconstruction Loss = 0.5717048645019531\n",
      "Epoch 97: Reconstruction Loss = 0.5712328553199768\n",
      "Epoch 98: Reconstruction Loss = 0.5732877850532532\n",
      "Epoch 99: Reconstruction Loss = 0.5737281441688538\n",
      "---Finished Autoencoder Training\n",
      "---Starting Autoencoder Training\n",
      "Epoch 0: Reconstruction Loss = 1.4554928541183472\n",
      "Epoch 1: Reconstruction Loss = 1.4547368288040161\n",
      "Epoch 2: Reconstruction Loss = 1.4507646560668945\n",
      "Epoch 3: Reconstruction Loss = 1.447290301322937\n",
      "Epoch 4: Reconstruction Loss = 1.4446591138839722\n",
      "Epoch 5: Reconstruction Loss = 1.4419260025024414\n",
      "Epoch 6: Reconstruction Loss = 1.4388536214828491\n",
      "Epoch 7: Reconstruction Loss = 1.4362760782241821\n",
      "Epoch 8: Reconstruction Loss = 1.433900237083435\n",
      "Epoch 9: Reconstruction Loss = 1.4299415349960327\n",
      "Epoch 10: Reconstruction Loss = 1.427665114402771\n",
      "Epoch 11: Reconstruction Loss = 1.4258023500442505\n",
      "Epoch 12: Reconstruction Loss = 1.421779990196228\n",
      "Epoch 13: Reconstruction Loss = 1.420073390007019\n",
      "Epoch 14: Reconstruction Loss = 1.4176688194274902\n",
      "Epoch 15: Reconstruction Loss = 1.4138940572738647\n",
      "Epoch 16: Reconstruction Loss = 1.4107747077941895\n",
      "Epoch 17: Reconstruction Loss = 1.4070104360580444\n",
      "Epoch 18: Reconstruction Loss = 1.4057998657226562\n",
      "Epoch 19: Reconstruction Loss = 1.4004368782043457\n",
      "Epoch 20: Reconstruction Loss = 1.398863434791565\n",
      "Epoch 21: Reconstruction Loss = 1.395914077758789\n",
      "Epoch 22: Reconstruction Loss = 1.3900755643844604\n",
      "Epoch 23: Reconstruction Loss = 1.388731598854065\n",
      "Epoch 24: Reconstruction Loss = 1.3852806091308594\n",
      "Epoch 25: Reconstruction Loss = 1.3835387229919434\n",
      "Epoch 26: Reconstruction Loss = 1.3780800104141235\n",
      "Epoch 27: Reconstruction Loss = 1.375789761543274\n",
      "Epoch 28: Reconstruction Loss = 1.372904896736145\n",
      "Epoch 29: Reconstruction Loss = 1.3671621084213257\n",
      "Epoch 30: Reconstruction Loss = 1.3636884689331055\n",
      "Epoch 31: Reconstruction Loss = 1.3607063293457031\n",
      "Epoch 32: Reconstruction Loss = 1.3522135019302368\n",
      "Epoch 33: Reconstruction Loss = 1.3506860733032227\n",
      "Epoch 34: Reconstruction Loss = 1.3444801568984985\n",
      "Epoch 35: Reconstruction Loss = 1.3438438177108765\n",
      "Epoch 36: Reconstruction Loss = 1.3379396200180054\n",
      "Epoch 37: Reconstruction Loss = 1.3306962251663208\n",
      "Epoch 38: Reconstruction Loss = 1.3277143239974976\n",
      "Epoch 39: Reconstruction Loss = 1.3211137056350708\n",
      "Epoch 40: Reconstruction Loss = 1.319399356842041\n",
      "Epoch 41: Reconstruction Loss = 1.3164995908737183\n",
      "Epoch 42: Reconstruction Loss = 1.3030091524124146\n",
      "Epoch 43: Reconstruction Loss = 1.3008116483688354\n",
      "Epoch 44: Reconstruction Loss = 1.2940798997879028\n",
      "Epoch 45: Reconstruction Loss = 1.2870192527770996\n",
      "Epoch 46: Reconstruction Loss = 1.2820180654525757\n",
      "Epoch 47: Reconstruction Loss = 1.276301383972168\n",
      "Epoch 48: Reconstruction Loss = 1.2679322957992554\n",
      "Epoch 49: Reconstruction Loss = 1.2655318975448608\n",
      "Epoch 50: Reconstruction Loss = 1.2592462301254272\n",
      "Epoch 51: Reconstruction Loss = 1.25413978099823\n",
      "Epoch 52: Reconstruction Loss = 1.2459235191345215\n",
      "Epoch 53: Reconstruction Loss = 1.2426831722259521\n",
      "Epoch 54: Reconstruction Loss = 1.2318881750106812\n",
      "Epoch 55: Reconstruction Loss = 1.2283648252487183\n",
      "Epoch 56: Reconstruction Loss = 1.221185326576233\n",
      "Epoch 57: Reconstruction Loss = 1.2146345376968384\n",
      "Epoch 58: Reconstruction Loss = 1.2033189535140991\n",
      "Epoch 59: Reconstruction Loss = 1.1983766555786133\n",
      "Epoch 60: Reconstruction Loss = 1.193200707435608\n",
      "Epoch 61: Reconstruction Loss = 1.189557433128357\n",
      "Epoch 62: Reconstruction Loss = 1.1793245077133179\n",
      "Epoch 63: Reconstruction Loss = 1.18002450466156\n",
      "Epoch 64: Reconstruction Loss = 1.1624445915222168\n",
      "Epoch 65: Reconstruction Loss = 1.1594642400741577\n",
      "Epoch 66: Reconstruction Loss = 1.151898741722107\n",
      "Epoch 67: Reconstruction Loss = 1.1391618251800537\n",
      "Epoch 68: Reconstruction Loss = 1.142215371131897\n",
      "Epoch 69: Reconstruction Loss = 1.1262680292129517\n",
      "Epoch 70: Reconstruction Loss = 1.1240577697753906\n",
      "Epoch 71: Reconstruction Loss = 1.1175717115402222\n",
      "Epoch 72: Reconstruction Loss = 1.1120288372039795\n",
      "Epoch 73: Reconstruction Loss = 1.1016629934310913\n",
      "Epoch 74: Reconstruction Loss = 1.0983701944351196\n",
      "Epoch 75: Reconstruction Loss = 1.087565541267395\n",
      "Epoch 76: Reconstruction Loss = 1.0851243734359741\n",
      "Epoch 77: Reconstruction Loss = 1.0767892599105835\n",
      "Epoch 78: Reconstruction Loss = 1.071546196937561\n",
      "Epoch 79: Reconstruction Loss = 1.0593196153640747\n",
      "Epoch 80: Reconstruction Loss = 1.0547188520431519\n",
      "Epoch 81: Reconstruction Loss = 1.0554652214050293\n",
      "Epoch 82: Reconstruction Loss = 1.0457873344421387\n",
      "Epoch 83: Reconstruction Loss = 1.0357056856155396\n",
      "Epoch 84: Reconstruction Loss = 1.0395663976669312\n",
      "Epoch 85: Reconstruction Loss = 1.0325816869735718\n",
      "Epoch 86: Reconstruction Loss = 1.025673747062683\n",
      "Epoch 87: Reconstruction Loss = 1.021081805229187\n",
      "Epoch 88: Reconstruction Loss = 1.0197227001190186\n",
      "Epoch 89: Reconstruction Loss = 1.0146498680114746\n",
      "Epoch 90: Reconstruction Loss = 1.0059295892715454\n",
      "Epoch 91: Reconstruction Loss = 0.9998553395271301\n",
      "Epoch 92: Reconstruction Loss = 0.9984394907951355\n",
      "Epoch 93: Reconstruction Loss = 0.9921934008598328\n",
      "Epoch 94: Reconstruction Loss = 0.9899794459342957\n",
      "Epoch 95: Reconstruction Loss = 0.9885709285736084\n",
      "Epoch 96: Reconstruction Loss = 0.9862346053123474\n",
      "Epoch 97: Reconstruction Loss = 0.9780295491218567\n",
      "Epoch 98: Reconstruction Loss = 0.9778571724891663\n",
      "Epoch 99: Reconstruction Loss = 0.9732736945152283\n",
      "---Finished Autoencoder Training\n",
      "---Starting Autoencoder Training\n",
      "Epoch 0: Reconstruction Loss = 1.4557608366012573\n",
      "Epoch 1: Reconstruction Loss = 1.435742974281311\n",
      "Epoch 2: Reconstruction Loss = 1.4178643226623535\n",
      "Epoch 3: Reconstruction Loss = 1.4031072854995728\n",
      "Epoch 4: Reconstruction Loss = 1.3849009275436401\n",
      "Epoch 5: Reconstruction Loss = 1.3653196096420288\n",
      "Epoch 6: Reconstruction Loss = 1.3415603637695312\n",
      "Epoch 7: Reconstruction Loss = 1.3148032426834106\n",
      "Epoch 8: Reconstruction Loss = 1.2891840934753418\n",
      "Epoch 9: Reconstruction Loss = 1.2643004655838013\n",
      "Epoch 10: Reconstruction Loss = 1.2385969161987305\n",
      "Epoch 11: Reconstruction Loss = 1.2119730710983276\n",
      "Epoch 12: Reconstruction Loss = 1.183639645576477\n",
      "Epoch 13: Reconstruction Loss = 1.1577414274215698\n",
      "Epoch 14: Reconstruction Loss = 1.1282401084899902\n",
      "Epoch 15: Reconstruction Loss = 1.0977462530136108\n",
      "Epoch 16: Reconstruction Loss = 1.0622214078903198\n",
      "Epoch 17: Reconstruction Loss = 1.0302528142929077\n",
      "Epoch 18: Reconstruction Loss = 0.9919140934944153\n",
      "Epoch 19: Reconstruction Loss = 0.9613236784934998\n",
      "Epoch 20: Reconstruction Loss = 0.9330711960792542\n",
      "Epoch 21: Reconstruction Loss = 0.9048301577568054\n",
      "Epoch 22: Reconstruction Loss = 0.8868785500526428\n",
      "Epoch 23: Reconstruction Loss = 0.8672139048576355\n",
      "Epoch 24: Reconstruction Loss = 0.8530125021934509\n",
      "Epoch 25: Reconstruction Loss = 0.8297653198242188\n",
      "Epoch 26: Reconstruction Loss = 0.8029984831809998\n",
      "Epoch 27: Reconstruction Loss = 0.7779991030693054\n",
      "Epoch 28: Reconstruction Loss = 0.7587971687316895\n",
      "Epoch 29: Reconstruction Loss = 0.7561323046684265\n",
      "Epoch 30: Reconstruction Loss = 0.751110851764679\n",
      "Epoch 31: Reconstruction Loss = 0.7266276478767395\n",
      "Epoch 32: Reconstruction Loss = 0.6915030479431152\n",
      "Epoch 33: Reconstruction Loss = 0.6712510585784912\n",
      "Epoch 34: Reconstruction Loss = 0.6593799591064453\n",
      "Epoch 35: Reconstruction Loss = 0.6519143581390381\n",
      "Epoch 36: Reconstruction Loss = 0.6477785706520081\n",
      "Epoch 37: Reconstruction Loss = 0.6352152228355408\n",
      "Epoch 38: Reconstruction Loss = 0.620665967464447\n",
      "Epoch 39: Reconstruction Loss = 0.5967667102813721\n",
      "Epoch 40: Reconstruction Loss = 0.5721568465232849\n",
      "Epoch 41: Reconstruction Loss = 0.5611732602119446\n",
      "Epoch 42: Reconstruction Loss = 0.5530224442481995\n",
      "Epoch 43: Reconstruction Loss = 0.5320066809654236\n",
      "Epoch 44: Reconstruction Loss = 0.5236209630966187\n",
      "Epoch 45: Reconstruction Loss = 0.524924635887146\n",
      "Epoch 46: Reconstruction Loss = 0.5306775569915771\n",
      "Epoch 47: Reconstruction Loss = 0.526814877986908\n",
      "Epoch 48: Reconstruction Loss = 0.5362334251403809\n",
      "Epoch 49: Reconstruction Loss = 0.5082321763038635\n",
      "Epoch 50: Reconstruction Loss = 0.5012626647949219\n",
      "Epoch 51: Reconstruction Loss = 0.5005537867546082\n",
      "Epoch 52: Reconstruction Loss = 0.49913063645362854\n",
      "Epoch 53: Reconstruction Loss = 0.49817129969596863\n",
      "Epoch 54: Reconstruction Loss = 0.4970839023590088\n",
      "Epoch 55: Reconstruction Loss = 0.4905138909816742\n",
      "Epoch 56: Reconstruction Loss = 0.48993682861328125\n",
      "Epoch 57: Reconstruction Loss = 0.4896415174007416\n",
      "Epoch 58: Reconstruction Loss = 0.4897131621837616\n",
      "Epoch 59: Reconstruction Loss = 0.4892663061618805\n",
      "Epoch 60: Reconstruction Loss = 0.4894197881221771\n",
      "Epoch 61: Reconstruction Loss = 0.49320849776268005\n",
      "Epoch 62: Reconstruction Loss = 0.48811182379722595\n",
      "Epoch 63: Reconstruction Loss = 0.4921107292175293\n",
      "Epoch 64: Reconstruction Loss = 0.49278125166893005\n",
      "Epoch 65: Reconstruction Loss = 0.4914751946926117\n",
      "Epoch 66: Reconstruction Loss = 0.4896089732646942\n",
      "Epoch 67: Reconstruction Loss = 0.49171194434165955\n",
      "Epoch 68: Reconstruction Loss = 0.4929293394088745\n",
      "Epoch 69: Reconstruction Loss = 0.4911084473133087\n",
      "Epoch 70: Reconstruction Loss = 0.4899660348892212\n",
      "Epoch 71: Reconstruction Loss = 0.4876722991466522\n",
      "Epoch 72: Reconstruction Loss = 0.48925766348838806\n",
      "Epoch 73: Reconstruction Loss = 0.4879786968231201\n",
      "Epoch 74: Reconstruction Loss = 0.48743414878845215\n",
      "Epoch 75: Reconstruction Loss = 0.48811352252960205\n",
      "Epoch 76: Reconstruction Loss = 0.4913260042667389\n",
      "Epoch 77: Reconstruction Loss = 0.488417387008667\n",
      "Epoch 78: Reconstruction Loss = 0.48728522658348083\n",
      "Epoch 79: Reconstruction Loss = 0.4872896373271942\n",
      "Epoch 80: Reconstruction Loss = 0.49216389656066895\n",
      "Epoch 81: Reconstruction Loss = 0.49257102608680725\n",
      "Epoch 82: Reconstruction Loss = 0.487508088350296\n",
      "Epoch 83: Reconstruction Loss = 0.489378958940506\n",
      "Epoch 84: Reconstruction Loss = 0.4874807298183441\n",
      "Epoch 85: Reconstruction Loss = 0.4884776175022125\n",
      "Epoch 86: Reconstruction Loss = 0.4894670248031616\n",
      "Epoch 87: Reconstruction Loss = 0.48704585433006287\n",
      "Epoch 88: Reconstruction Loss = 0.4868508577346802\n",
      "Epoch 89: Reconstruction Loss = 0.4890061616897583\n",
      "Epoch 90: Reconstruction Loss = 0.48661288619041443\n",
      "Epoch 91: Reconstruction Loss = 0.489086389541626\n",
      "Epoch 92: Reconstruction Loss = 0.4887465536594391\n",
      "Epoch 93: Reconstruction Loss = 0.48854660987854004\n",
      "Epoch 94: Reconstruction Loss = 0.48643290996551514\n",
      "Epoch 95: Reconstruction Loss = 0.4871402680873871\n",
      "Epoch 96: Reconstruction Loss = 0.4878089725971222\n",
      "Epoch 97: Reconstruction Loss = 0.48716089129447937\n",
      "Epoch 98: Reconstruction Loss = 0.4970947206020355\n",
      "Epoch 99: Reconstruction Loss = 0.5102651715278625\n",
      "---Finished Autoencoder Training\n",
      "---Starting Generative Training\n",
      "Epoch 0: Supervised Loss = 3.3042595386505127 Unsupervised Loss G = 0.17213141918182373 Unsupervised Loss C = 0.7448433041572571 Gradient Penalty = 0.10082284361124039\n",
      "Epoch 1: Supervised Loss = 3.2730977535247803 Unsupervised Loss G = -0.007279588375240564 Unsupervised Loss C = 1.5580543279647827 Gradient Penalty = 0.06026412174105644\n",
      "Epoch 2: Supervised Loss = 3.204580068588257 Unsupervised Loss G = -0.07691975682973862 Unsupervised Loss C = 1.754231333732605 Gradient Penalty = 0.06184849515557289\n",
      "Epoch 3: Supervised Loss = 3.127173662185669 Unsupervised Loss G = -0.16519926488399506 Unsupervised Loss C = 1.7972227334976196 Gradient Penalty = 0.0607716366648674\n",
      "Epoch 4: Supervised Loss = 3.17809796333313 Unsupervised Loss G = -0.2296789437532425 Unsupervised Loss C = 1.8093174695968628 Gradient Penalty = 0.0614355131983757\n",
      "Epoch 5: Supervised Loss = 3.08681321144104 Unsupervised Loss G = -0.22917211055755615 Unsupervised Loss C = 1.8108253479003906 Gradient Penalty = 0.06007813289761543\n",
      "Epoch 6: Supervised Loss = 2.9915332794189453 Unsupervised Loss G = -0.28033384680747986 Unsupervised Loss C = 1.8118445873260498 Gradient Penalty = 0.06070827692747116\n",
      "Epoch 7: Supervised Loss = 2.9124205112457275 Unsupervised Loss G = -0.29880282282829285 Unsupervised Loss C = 1.810838222503662 Gradient Penalty = 0.060521092265844345\n",
      "Epoch 8: Supervised Loss = 2.800191640853882 Unsupervised Loss G = -0.31633758544921875 Unsupervised Loss C = 1.8087364435195923 Gradient Penalty = 0.06019575521349907\n",
      "Epoch 9: Supervised Loss = 2.9475433826446533 Unsupervised Loss G = -0.30611059069633484 Unsupervised Loss C = 1.8050272464752197 Gradient Penalty = 0.05986088141798973\n",
      "Epoch 10: Supervised Loss = 2.828775405883789 Unsupervised Loss G = -0.3272053897380829 Unsupervised Loss C = 1.8018486499786377 Gradient Penalty = 0.059309083968400955\n",
      "Epoch 11: Supervised Loss = 2.7176878452301025 Unsupervised Loss G = -0.37048473954200745 Unsupervised Loss C = 1.8034014701843262 Gradient Penalty = 0.059846099466085434\n",
      "Epoch 12: Supervised Loss = 2.72251296043396 Unsupervised Loss G = -0.3760048449039459 Unsupervised Loss C = 1.7958264350891113 Gradient Penalty = 0.05885746330022812\n",
      "Epoch 13: Supervised Loss = 2.681879997253418 Unsupervised Loss G = -0.4012569487094879 Unsupervised Loss C = 1.7933001518249512 Gradient Penalty = 0.05872543156147003\n",
      "Epoch 14: Supervised Loss = 2.516810655593872 Unsupervised Loss G = -0.4448094367980957 Unsupervised Loss C = 1.7924845218658447 Gradient Penalty = 0.05952029675245285\n",
      "Epoch 15: Supervised Loss = 2.4972572326660156 Unsupervised Loss G = -0.44594988226890564 Unsupervised Loss C = 1.78453528881073 Gradient Penalty = 0.05836229398846626\n",
      "Epoch 16: Supervised Loss = 2.4164555072784424 Unsupervised Loss G = -0.4458509683609009 Unsupervised Loss C = 1.7777031660079956 Gradient Penalty = 0.058675527572631836\n",
      "Epoch 17: Supervised Loss = 2.342116594314575 Unsupervised Loss G = -0.45463189482688904 Unsupervised Loss C = 1.7659072875976562 Gradient Penalty = 0.05802639201283455\n",
      "Epoch 18: Supervised Loss = 2.387957811355591 Unsupervised Loss G = -0.5092690587043762 Unsupervised Loss C = 1.7513126134872437 Gradient Penalty = 0.05711180344223976\n",
      "Epoch 19: Supervised Loss = 2.239558458328247 Unsupervised Loss G = -0.5255281329154968 Unsupervised Loss C = 1.742170810699463 Gradient Penalty = 0.05749199166893959\n",
      "Epoch 20: Supervised Loss = 2.029285430908203 Unsupervised Loss G = -0.5389171242713928 Unsupervised Loss C = 1.7272639274597168 Gradient Penalty = 0.055999305099248886\n",
      "Epoch 21: Supervised Loss = 1.9534536600112915 Unsupervised Loss G = -0.5145809650421143 Unsupervised Loss C = 1.7136352062225342 Gradient Penalty = 0.054930444806814194\n",
      "Epoch 22: Supervised Loss = 1.9178282022476196 Unsupervised Loss G = -0.522023618221283 Unsupervised Loss C = 1.7020634412765503 Gradient Penalty = 0.05531003698706627\n",
      "Epoch 23: Supervised Loss = 1.8207759857177734 Unsupervised Loss G = -0.4992019236087799 Unsupervised Loss C = 1.6832066774368286 Gradient Penalty = 0.05367333069443703\n",
      "Epoch 24: Supervised Loss = 1.6275348663330078 Unsupervised Loss G = -0.520324170589447 Unsupervised Loss C = 1.6646796464920044 Gradient Penalty = 0.052706170827150345\n",
      "Epoch 25: Supervised Loss = 1.5362157821655273 Unsupervised Loss G = -0.5272560715675354 Unsupervised Loss C = 1.6485443115234375 Gradient Penalty = 0.052498165518045425\n",
      "Epoch 26: Supervised Loss = 1.4232134819030762 Unsupervised Loss G = -0.5846652388572693 Unsupervised Loss C = 1.6302952766418457 Gradient Penalty = 0.05232081562280655\n",
      "Epoch 27: Supervised Loss = 1.3546894788742065 Unsupervised Loss G = -0.6019672751426697 Unsupervised Loss C = 1.613325834274292 Gradient Penalty = 0.05067373812198639\n",
      "Epoch 28: Supervised Loss = 1.3021360635757446 Unsupervised Loss G = -0.6635510921478271 Unsupervised Loss C = 1.6052569150924683 Gradient Penalty = 0.050892822444438934\n",
      "Epoch 29: Supervised Loss = 1.0270897150039673 Unsupervised Loss G = -0.7531996369361877 Unsupervised Loss C = 1.5954794883728027 Gradient Penalty = 0.05089950188994408\n",
      "Epoch 30: Supervised Loss = 1.0801094770431519 Unsupervised Loss G = -0.7750080227851868 Unsupervised Loss C = 1.5898864269256592 Gradient Penalty = 0.05049561709165573\n",
      "Epoch 31: Supervised Loss = 0.9048380851745605 Unsupervised Loss G = -0.8550462126731873 Unsupervised Loss C = 1.5914132595062256 Gradient Penalty = 0.051166828721761703\n",
      "Epoch 32: Supervised Loss = 0.8024078011512756 Unsupervised Loss G = -0.8696287274360657 Unsupervised Loss C = 1.5873262882232666 Gradient Penalty = 0.0514349490404129\n",
      "Epoch 33: Supervised Loss = 0.7509101033210754 Unsupervised Loss G = -0.8249115347862244 Unsupervised Loss C = 1.5825629234313965 Gradient Penalty = 0.05095468834042549\n",
      "Epoch 34: Supervised Loss = 0.7710917592048645 Unsupervised Loss G = -0.7724260687828064 Unsupervised Loss C = 1.5751076936721802 Gradient Penalty = 0.051232196390628815\n",
      "Epoch 35: Supervised Loss = 0.6932222247123718 Unsupervised Loss G = -0.741393506526947 Unsupervised Loss C = 1.5680644512176514 Gradient Penalty = 0.05086233839392662\n",
      "Epoch 36: Supervised Loss = 0.6230906844139099 Unsupervised Loss G = -0.7254069447517395 Unsupervised Loss C = 1.5580089092254639 Gradient Penalty = 0.05082707107067108\n",
      "Epoch 37: Supervised Loss = 0.5946359038352966 Unsupervised Loss G = -0.7178133130073547 Unsupervised Loss C = 1.5412827730178833 Gradient Penalty = 0.04986605793237686\n",
      "Epoch 38: Supervised Loss = 0.5992823839187622 Unsupervised Loss G = -0.7092204093933105 Unsupervised Loss C = 1.5221294164657593 Gradient Penalty = 0.04862568527460098\n",
      "Epoch 39: Supervised Loss = 0.5439448356628418 Unsupervised Loss G = -0.7383365035057068 Unsupervised Loss C = 1.5040018558502197 Gradient Penalty = 0.04882510378956795\n",
      "Epoch 40: Supervised Loss = 0.5711285471916199 Unsupervised Loss G = -0.7250667214393616 Unsupervised Loss C = 1.48298978805542 Gradient Penalty = 0.04738955199718475\n",
      "Epoch 41: Supervised Loss = 0.5479370951652527 Unsupervised Loss G = -0.755361020565033 Unsupervised Loss C = 1.4664214849472046 Gradient Penalty = 0.047880589962005615\n",
      "Epoch 42: Supervised Loss = 0.45409801602363586 Unsupervised Loss G = -0.757645308971405 Unsupervised Loss C = 1.43865168094635 Gradient Penalty = 0.04650016501545906\n",
      "Epoch 43: Supervised Loss = 0.4826543629169464 Unsupervised Loss G = -0.7085940837860107 Unsupervised Loss C = 1.421934962272644 Gradient Penalty = 0.04637547954916954\n",
      "Epoch 44: Supervised Loss = 0.4320816993713379 Unsupervised Loss G = -0.7573893666267395 Unsupervised Loss C = 1.4090551137924194 Gradient Penalty = 0.046227674931287766\n",
      "Epoch 45: Supervised Loss = 0.48955926299095154 Unsupervised Loss G = -0.6953418850898743 Unsupervised Loss C = 1.3903934955596924 Gradient Penalty = 0.04511170834302902\n",
      "Epoch 46: Supervised Loss = 0.4508141279220581 Unsupervised Loss G = -0.6825048327445984 Unsupervised Loss C = 1.374373197555542 Gradient Penalty = 0.04473492130637169\n",
      "Epoch 47: Supervised Loss = 0.4217127561569214 Unsupervised Loss G = -0.6517795324325562 Unsupervised Loss C = 1.3598334789276123 Gradient Penalty = 0.044002994894981384\n",
      "Epoch 48: Supervised Loss = 0.44290873408317566 Unsupervised Loss G = -0.633526086807251 Unsupervised Loss C = 1.341317892074585 Gradient Penalty = 0.04268805310130119\n",
      "Epoch 49: Supervised Loss = 0.47643348574638367 Unsupervised Loss G = -0.6358924508094788 Unsupervised Loss C = 1.324459433555603 Gradient Penalty = 0.04290313273668289\n",
      "---Finished Generative Training\n",
      "---Starting Autoencoder Training\n",
      "Epoch 0: Reconstruction Loss = 1.428571343421936\n",
      "Epoch 1: Reconstruction Loss = 1.4041444063186646\n",
      "Epoch 2: Reconstruction Loss = 1.3770122528076172\n",
      "Epoch 3: Reconstruction Loss = 1.3497809171676636\n",
      "Epoch 4: Reconstruction Loss = 1.3223975896835327\n",
      "Epoch 5: Reconstruction Loss = 1.2997207641601562\n",
      "Epoch 6: Reconstruction Loss = 1.2772923707962036\n",
      "Epoch 7: Reconstruction Loss = 1.2533611059188843\n",
      "Epoch 8: Reconstruction Loss = 1.2337085008621216\n",
      "Epoch 9: Reconstruction Loss = 1.2168679237365723\n",
      "Epoch 10: Reconstruction Loss = 1.203024983406067\n",
      "Epoch 11: Reconstruction Loss = 1.1887545585632324\n",
      "Epoch 12: Reconstruction Loss = 1.1492117643356323\n",
      "Epoch 13: Reconstruction Loss = 1.1170536279678345\n",
      "Epoch 14: Reconstruction Loss = 1.066898226737976\n",
      "Epoch 15: Reconstruction Loss = 0.9888214468955994\n",
      "Epoch 16: Reconstruction Loss = 0.9254942536354065\n",
      "Epoch 17: Reconstruction Loss = 0.8546857237815857\n",
      "Epoch 18: Reconstruction Loss = 0.7815110683441162\n",
      "Epoch 19: Reconstruction Loss = 0.7133036255836487\n",
      "Epoch 20: Reconstruction Loss = 0.662663996219635\n",
      "Epoch 21: Reconstruction Loss = 0.616920530796051\n",
      "Epoch 22: Reconstruction Loss = 0.5798931121826172\n",
      "Epoch 23: Reconstruction Loss = 0.5276697278022766\n",
      "Epoch 24: Reconstruction Loss = 0.4855393171310425\n",
      "Epoch 25: Reconstruction Loss = 0.44627416133880615\n",
      "Epoch 26: Reconstruction Loss = 0.4087328612804413\n",
      "Epoch 27: Reconstruction Loss = 0.3721926212310791\n",
      "Epoch 28: Reconstruction Loss = 0.3329590857028961\n",
      "Epoch 29: Reconstruction Loss = 0.3060574531555176\n",
      "Epoch 30: Reconstruction Loss = 0.27175453305244446\n",
      "Epoch 31: Reconstruction Loss = 0.25280794501304626\n",
      "Epoch 32: Reconstruction Loss = 0.23170910775661469\n",
      "Epoch 33: Reconstruction Loss = 0.21694588661193848\n",
      "Epoch 34: Reconstruction Loss = 0.20498941838741302\n",
      "Epoch 35: Reconstruction Loss = 0.1958918571472168\n",
      "Epoch 36: Reconstruction Loss = 0.19162672758102417\n",
      "Epoch 37: Reconstruction Loss = 0.18264061212539673\n",
      "Epoch 38: Reconstruction Loss = 0.18220216035842896\n",
      "Epoch 39: Reconstruction Loss = 0.1799776703119278\n",
      "Epoch 40: Reconstruction Loss = 0.1782063990831375\n",
      "Epoch 41: Reconstruction Loss = 0.17252151668071747\n",
      "Epoch 42: Reconstruction Loss = 0.17364948987960815\n",
      "Epoch 43: Reconstruction Loss = 0.18041956424713135\n",
      "Epoch 44: Reconstruction Loss = 0.17351055145263672\n",
      "Epoch 45: Reconstruction Loss = 0.17577993869781494\n",
      "Epoch 46: Reconstruction Loss = 0.17201854288578033\n",
      "Epoch 47: Reconstruction Loss = 0.17343302071094513\n",
      "Epoch 48: Reconstruction Loss = 0.16869507730007172\n",
      "Epoch 49: Reconstruction Loss = 0.16674935817718506\n",
      "Epoch 50: Reconstruction Loss = 0.1686517596244812\n",
      "Epoch 51: Reconstruction Loss = 0.1700582355260849\n",
      "Epoch 52: Reconstruction Loss = 0.17688415944576263\n",
      "Epoch 53: Reconstruction Loss = 0.16855929791927338\n",
      "Epoch 54: Reconstruction Loss = 0.16764777898788452\n",
      "Epoch 55: Reconstruction Loss = 0.17176097631454468\n",
      "Epoch 56: Reconstruction Loss = 0.16586297750473022\n",
      "Epoch 57: Reconstruction Loss = 0.17086584866046906\n",
      "Epoch 58: Reconstruction Loss = 0.16620124876499176\n",
      "Epoch 59: Reconstruction Loss = 0.16934281587600708\n",
      "Epoch 60: Reconstruction Loss = 0.17197012901306152\n",
      "Epoch 61: Reconstruction Loss = 0.16989533603191376\n",
      "Epoch 62: Reconstruction Loss = 0.16459029912948608\n",
      "Epoch 63: Reconstruction Loss = 0.1663678139448166\n",
      "Epoch 64: Reconstruction Loss = 0.16735386848449707\n",
      "Epoch 65: Reconstruction Loss = 0.16440773010253906\n",
      "Epoch 66: Reconstruction Loss = 0.1689564734697342\n",
      "Epoch 67: Reconstruction Loss = 0.1661258190870285\n",
      "Epoch 68: Reconstruction Loss = 0.16192126274108887\n",
      "Epoch 69: Reconstruction Loss = 0.15990664064884186\n",
      "Epoch 70: Reconstruction Loss = 0.1652669906616211\n",
      "Epoch 71: Reconstruction Loss = 0.1593991219997406\n",
      "Epoch 72: Reconstruction Loss = 0.16226552426815033\n",
      "Epoch 73: Reconstruction Loss = 0.16162501275539398\n",
      "Epoch 74: Reconstruction Loss = 0.16135577857494354\n",
      "Epoch 75: Reconstruction Loss = 0.16361920535564423\n",
      "Epoch 76: Reconstruction Loss = 0.16144482791423798\n",
      "Epoch 77: Reconstruction Loss = 0.16121052205562592\n",
      "Epoch 78: Reconstruction Loss = 0.1624596267938614\n",
      "Epoch 79: Reconstruction Loss = 0.16354410350322723\n",
      "Epoch 80: Reconstruction Loss = 0.1609378457069397\n",
      "Epoch 81: Reconstruction Loss = 0.1639445573091507\n",
      "Epoch 82: Reconstruction Loss = 0.16314031183719635\n",
      "Epoch 83: Reconstruction Loss = 0.16149072349071503\n",
      "Epoch 84: Reconstruction Loss = 0.15895019471645355\n",
      "Epoch 85: Reconstruction Loss = 0.16097229719161987\n",
      "Epoch 86: Reconstruction Loss = 0.1600804179906845\n",
      "Epoch 87: Reconstruction Loss = 0.15861459076404572\n",
      "Epoch 88: Reconstruction Loss = 0.1606418341398239\n",
      "Epoch 89: Reconstruction Loss = 0.15856607258319855\n",
      "Epoch 90: Reconstruction Loss = 0.16013091802597046\n",
      "Epoch 91: Reconstruction Loss = 0.1630137711763382\n",
      "Epoch 92: Reconstruction Loss = 0.15959392488002777\n",
      "Epoch 93: Reconstruction Loss = 0.15943647921085358\n",
      "Epoch 94: Reconstruction Loss = 0.15890765190124512\n",
      "Epoch 95: Reconstruction Loss = 0.160474956035614\n",
      "Epoch 96: Reconstruction Loss = 0.16180193424224854\n",
      "Epoch 97: Reconstruction Loss = 0.15969520807266235\n",
      "Epoch 98: Reconstruction Loss = 0.16386215388774872\n",
      "Epoch 99: Reconstruction Loss = 0.15832357108592987\n",
      "---Finished Autoencoder Training\n",
      "---Starting Autoencoder Training\n",
      "Epoch 0: Reconstruction Loss = 1.43831205368042\n",
      "Epoch 1: Reconstruction Loss = 1.4357284307479858\n",
      "Epoch 2: Reconstruction Loss = 1.432970404624939\n",
      "Epoch 3: Reconstruction Loss = 1.4308314323425293\n",
      "Epoch 4: Reconstruction Loss = 1.4283102750778198\n",
      "Epoch 5: Reconstruction Loss = 1.4257351160049438\n",
      "Epoch 6: Reconstruction Loss = 1.423457145690918\n",
      "Epoch 7: Reconstruction Loss = 1.4206591844558716\n",
      "Epoch 8: Reconstruction Loss = 1.4179335832595825\n",
      "Epoch 9: Reconstruction Loss = 1.4160643815994263\n",
      "Epoch 10: Reconstruction Loss = 1.4140115976333618\n",
      "Epoch 11: Reconstruction Loss = 1.4116144180297852\n",
      "Epoch 12: Reconstruction Loss = 1.4079670906066895\n",
      "Epoch 13: Reconstruction Loss = 1.405340552330017\n",
      "Epoch 14: Reconstruction Loss = 1.4037084579467773\n",
      "Epoch 15: Reconstruction Loss = 1.400683879852295\n",
      "Epoch 16: Reconstruction Loss = 1.39871346950531\n",
      "Epoch 17: Reconstruction Loss = 1.394932746887207\n",
      "Epoch 18: Reconstruction Loss = 1.3922537565231323\n",
      "Epoch 19: Reconstruction Loss = 1.3898247480392456\n",
      "Epoch 20: Reconstruction Loss = 1.3849401473999023\n",
      "Epoch 21: Reconstruction Loss = 1.3835645914077759\n",
      "Epoch 22: Reconstruction Loss = 1.3802300691604614\n",
      "Epoch 23: Reconstruction Loss = 1.3768950700759888\n",
      "Epoch 24: Reconstruction Loss = 1.373738408088684\n",
      "Epoch 25: Reconstruction Loss = 1.3715953826904297\n",
      "Epoch 26: Reconstruction Loss = 1.3683524131774902\n",
      "Epoch 27: Reconstruction Loss = 1.3630114793777466\n",
      "Epoch 28: Reconstruction Loss = 1.3585758209228516\n",
      "Epoch 29: Reconstruction Loss = 1.3569388389587402\n",
      "Epoch 30: Reconstruction Loss = 1.3524717092514038\n",
      "Epoch 31: Reconstruction Loss = 1.3489924669265747\n",
      "Epoch 32: Reconstruction Loss = 1.3440035581588745\n",
      "Epoch 33: Reconstruction Loss = 1.3429155349731445\n",
      "Epoch 34: Reconstruction Loss = 1.3380385637283325\n",
      "Epoch 35: Reconstruction Loss = 1.332152247428894\n",
      "Epoch 36: Reconstruction Loss = 1.330604076385498\n",
      "Epoch 37: Reconstruction Loss = 1.32563316822052\n",
      "Epoch 38: Reconstruction Loss = 1.3198704719543457\n",
      "Epoch 39: Reconstruction Loss = 1.3171406984329224\n",
      "Epoch 40: Reconstruction Loss = 1.311799168586731\n",
      "Epoch 41: Reconstruction Loss = 1.3053264617919922\n",
      "Epoch 42: Reconstruction Loss = 1.3055139780044556\n",
      "Epoch 43: Reconstruction Loss = 1.2944368124008179\n",
      "Epoch 44: Reconstruction Loss = 1.2931922674179077\n",
      "Epoch 45: Reconstruction Loss = 1.2899842262268066\n",
      "Epoch 46: Reconstruction Loss = 1.2844942808151245\n",
      "Epoch 47: Reconstruction Loss = 1.2788830995559692\n",
      "Epoch 48: Reconstruction Loss = 1.2794312238693237\n",
      "Epoch 49: Reconstruction Loss = 1.2686773538589478\n",
      "Epoch 50: Reconstruction Loss = 1.258921504020691\n",
      "Epoch 51: Reconstruction Loss = 1.2630947828292847\n",
      "Epoch 52: Reconstruction Loss = 1.2530633211135864\n",
      "Epoch 53: Reconstruction Loss = 1.251402497291565\n",
      "Epoch 54: Reconstruction Loss = 1.245442509651184\n",
      "Epoch 55: Reconstruction Loss = 1.2415696382522583\n",
      "Epoch 56: Reconstruction Loss = 1.2297354936599731\n",
      "Epoch 57: Reconstruction Loss = 1.2284570932388306\n",
      "Epoch 58: Reconstruction Loss = 1.224120020866394\n",
      "Epoch 59: Reconstruction Loss = 1.2203654050827026\n",
      "Epoch 60: Reconstruction Loss = 1.207912564277649\n",
      "Epoch 61: Reconstruction Loss = 1.2008956670761108\n",
      "Epoch 62: Reconstruction Loss = 1.2061251401901245\n",
      "Epoch 63: Reconstruction Loss = 1.1970618963241577\n",
      "Epoch 64: Reconstruction Loss = 1.1868091821670532\n",
      "Epoch 65: Reconstruction Loss = 1.1851987838745117\n",
      "Epoch 66: Reconstruction Loss = 1.1769219636917114\n",
      "Epoch 67: Reconstruction Loss = 1.1709431409835815\n",
      "Epoch 68: Reconstruction Loss = 1.1732615232467651\n",
      "Epoch 69: Reconstruction Loss = 1.1614775657653809\n",
      "Epoch 70: Reconstruction Loss = 1.157638430595398\n",
      "Epoch 71: Reconstruction Loss = 1.1487849950790405\n",
      "Epoch 72: Reconstruction Loss = 1.1408847570419312\n",
      "Epoch 73: Reconstruction Loss = 1.1356115341186523\n",
      "Epoch 74: Reconstruction Loss = 1.127484917640686\n",
      "Epoch 75: Reconstruction Loss = 1.128659725189209\n",
      "Epoch 76: Reconstruction Loss = 1.1205888986587524\n",
      "Epoch 77: Reconstruction Loss = 1.1117476224899292\n",
      "Epoch 78: Reconstruction Loss = 1.1052292585372925\n",
      "Epoch 79: Reconstruction Loss = 1.0984169244766235\n",
      "Epoch 80: Reconstruction Loss = 1.0992728471755981\n",
      "Epoch 81: Reconstruction Loss = 1.0857701301574707\n",
      "Epoch 82: Reconstruction Loss = 1.0900520086288452\n",
      "Epoch 83: Reconstruction Loss = 1.0783687829971313\n",
      "Epoch 84: Reconstruction Loss = 1.0735536813735962\n",
      "Epoch 85: Reconstruction Loss = 1.0669065713882446\n",
      "Epoch 86: Reconstruction Loss = 1.057813048362732\n",
      "Epoch 87: Reconstruction Loss = 1.053825855255127\n",
      "Epoch 88: Reconstruction Loss = 1.0452502965927124\n",
      "Epoch 89: Reconstruction Loss = 1.0444622039794922\n",
      "Epoch 90: Reconstruction Loss = 1.0372943878173828\n",
      "Epoch 91: Reconstruction Loss = 1.023586630821228\n",
      "Epoch 92: Reconstruction Loss = 1.0218898057937622\n",
      "Epoch 93: Reconstruction Loss = 1.0203925371170044\n",
      "Epoch 94: Reconstruction Loss = 1.0114717483520508\n",
      "Epoch 95: Reconstruction Loss = 1.0065851211547852\n",
      "Epoch 96: Reconstruction Loss = 1.000462293624878\n",
      "Epoch 97: Reconstruction Loss = 0.9939961433410645\n",
      "Epoch 98: Reconstruction Loss = 0.9944058060646057\n",
      "Epoch 99: Reconstruction Loss = 0.9830628037452698\n",
      "---Finished Autoencoder Training\n",
      "---Starting Autoencoder Training\n",
      "Epoch 0: Reconstruction Loss = 1.4254212379455566\n",
      "Epoch 1: Reconstruction Loss = 1.399896264076233\n",
      "Epoch 2: Reconstruction Loss = 1.3725124597549438\n",
      "Epoch 3: Reconstruction Loss = 1.3452749252319336\n",
      "Epoch 4: Reconstruction Loss = 1.3208556175231934\n",
      "Epoch 5: Reconstruction Loss = 1.288716197013855\n",
      "Epoch 6: Reconstruction Loss = 1.2644644975662231\n",
      "Epoch 7: Reconstruction Loss = 1.2332178354263306\n",
      "Epoch 8: Reconstruction Loss = 1.2274478673934937\n",
      "Epoch 9: Reconstruction Loss = 1.2024550437927246\n",
      "Epoch 10: Reconstruction Loss = 1.1889052391052246\n",
      "Epoch 11: Reconstruction Loss = 1.1677623987197876\n",
      "Epoch 12: Reconstruction Loss = 1.1327928304672241\n",
      "Epoch 13: Reconstruction Loss = 1.096811056137085\n",
      "Epoch 14: Reconstruction Loss = 1.050106406211853\n",
      "Epoch 15: Reconstruction Loss = 0.9941624999046326\n",
      "Epoch 16: Reconstruction Loss = 0.9233610033988953\n",
      "Epoch 17: Reconstruction Loss = 0.842089831829071\n",
      "Epoch 18: Reconstruction Loss = 0.748687744140625\n",
      "Epoch 19: Reconstruction Loss = 0.6810892224311829\n",
      "Epoch 20: Reconstruction Loss = 0.6185949444770813\n",
      "Epoch 21: Reconstruction Loss = 0.5699820518493652\n",
      "Epoch 22: Reconstruction Loss = 0.5335359573364258\n",
      "Epoch 23: Reconstruction Loss = 0.5054047703742981\n",
      "Epoch 24: Reconstruction Loss = 0.4773003160953522\n",
      "Epoch 25: Reconstruction Loss = 0.4547481834888458\n",
      "Epoch 26: Reconstruction Loss = 0.4337140619754791\n",
      "Epoch 27: Reconstruction Loss = 0.4103337526321411\n",
      "Epoch 28: Reconstruction Loss = 0.38512250781059265\n",
      "Epoch 29: Reconstruction Loss = 0.3613468408584595\n",
      "Epoch 30: Reconstruction Loss = 0.33695098757743835\n",
      "Epoch 31: Reconstruction Loss = 0.31603220105171204\n",
      "Epoch 32: Reconstruction Loss = 0.29995450377464294\n",
      "Epoch 33: Reconstruction Loss = 0.28855088353157043\n",
      "Epoch 34: Reconstruction Loss = 0.27625539898872375\n",
      "Epoch 35: Reconstruction Loss = 0.26670971512794495\n",
      "Epoch 36: Reconstruction Loss = 0.26487061381340027\n",
      "Epoch 37: Reconstruction Loss = 0.25608542561531067\n",
      "Epoch 38: Reconstruction Loss = 0.25370725989341736\n",
      "Epoch 39: Reconstruction Loss = 0.25154924392700195\n",
      "Epoch 40: Reconstruction Loss = 0.25357314944267273\n",
      "Epoch 41: Reconstruction Loss = 0.2517145276069641\n",
      "Epoch 42: Reconstruction Loss = 0.24923710525035858\n",
      "Epoch 43: Reconstruction Loss = 0.2503822147846222\n",
      "Epoch 44: Reconstruction Loss = 0.25267645716667175\n",
      "Epoch 45: Reconstruction Loss = 0.25061437487602234\n",
      "Epoch 46: Reconstruction Loss = 0.25025853514671326\n",
      "Epoch 47: Reconstruction Loss = 0.25028082728385925\n",
      "Epoch 48: Reconstruction Loss = 0.24742919206619263\n",
      "Epoch 49: Reconstruction Loss = 0.24710185825824738\n",
      "Epoch 50: Reconstruction Loss = 0.24791055917739868\n",
      "Epoch 51: Reconstruction Loss = 0.24781520664691925\n",
      "Epoch 52: Reconstruction Loss = 0.24777443706989288\n",
      "Epoch 53: Reconstruction Loss = 0.24671059846878052\n",
      "Epoch 54: Reconstruction Loss = 0.24753518402576447\n",
      "Epoch 55: Reconstruction Loss = 0.24772708117961884\n",
      "Epoch 56: Reconstruction Loss = 0.24685482680797577\n",
      "Epoch 57: Reconstruction Loss = 0.24709661304950714\n",
      "Epoch 58: Reconstruction Loss = 0.24747204780578613\n",
      "Epoch 59: Reconstruction Loss = 0.24622638523578644\n",
      "Epoch 60: Reconstruction Loss = 0.24620069563388824\n",
      "Epoch 61: Reconstruction Loss = 0.2460107058286667\n",
      "Epoch 62: Reconstruction Loss = 0.24726641178131104\n",
      "Epoch 63: Reconstruction Loss = 0.247505784034729\n",
      "Epoch 64: Reconstruction Loss = 0.24829156696796417\n",
      "Epoch 65: Reconstruction Loss = 0.2459782510995865\n",
      "Epoch 66: Reconstruction Loss = 0.24624554812908173\n",
      "Epoch 67: Reconstruction Loss = 0.24599695205688477\n",
      "Epoch 68: Reconstruction Loss = 0.24612325429916382\n",
      "Epoch 69: Reconstruction Loss = 0.24579982459545135\n",
      "Epoch 70: Reconstruction Loss = 0.24574680626392365\n",
      "Epoch 71: Reconstruction Loss = 0.24756141006946564\n",
      "Epoch 72: Reconstruction Loss = 0.2461228221654892\n",
      "Epoch 73: Reconstruction Loss = 0.24649186432361603\n",
      "Epoch 74: Reconstruction Loss = 0.24750345945358276\n",
      "Epoch 75: Reconstruction Loss = 0.24731819331645966\n",
      "Epoch 76: Reconstruction Loss = 0.24557767808437347\n",
      "Epoch 77: Reconstruction Loss = 0.24935384094715118\n",
      "Epoch 78: Reconstruction Loss = 0.24595995247364044\n",
      "Epoch 79: Reconstruction Loss = 0.24651463329792023\n",
      "Epoch 80: Reconstruction Loss = 0.24548523128032684\n",
      "Epoch 81: Reconstruction Loss = 0.24551208317279816\n",
      "Epoch 82: Reconstruction Loss = 0.24646912515163422\n",
      "Epoch 83: Reconstruction Loss = 0.24562124907970428\n",
      "Epoch 84: Reconstruction Loss = 0.2464216947555542\n",
      "Epoch 85: Reconstruction Loss = 0.24548058211803436\n",
      "Epoch 86: Reconstruction Loss = 0.24542464315891266\n",
      "Epoch 87: Reconstruction Loss = 0.24571776390075684\n",
      "Epoch 88: Reconstruction Loss = 0.24606864154338837\n",
      "Epoch 89: Reconstruction Loss = 0.24686282873153687\n",
      "Epoch 90: Reconstruction Loss = 0.24513907730579376\n",
      "Epoch 91: Reconstruction Loss = 0.24525345861911774\n",
      "Epoch 92: Reconstruction Loss = 0.24659235775470734\n",
      "Epoch 93: Reconstruction Loss = 0.24672210216522217\n",
      "Epoch 94: Reconstruction Loss = 0.24545709788799286\n",
      "Epoch 95: Reconstruction Loss = 0.24521124362945557\n",
      "Epoch 96: Reconstruction Loss = 0.24453699588775635\n",
      "Epoch 97: Reconstruction Loss = 0.24524439871311188\n",
      "Epoch 98: Reconstruction Loss = 0.2454417496919632\n",
      "Epoch 99: Reconstruction Loss = 0.24500854313373566\n",
      "---Finished Autoencoder Training\n",
      "---Starting Generative Training\n",
      "Epoch 0: Supervised Loss = 2.256547689437866 Unsupervised Loss G = -0.034176018089056015 Unsupervised Loss C = 0.958628237247467 Gradient Penalty = 0.1409425586462021\n",
      "Epoch 1: Supervised Loss = 2.3549063205718994 Unsupervised Loss G = -0.2556321918964386 Unsupervised Loss C = 1.6313400268554688 Gradient Penalty = 0.06324077397584915\n",
      "Epoch 2: Supervised Loss = 2.3047170639038086 Unsupervised Loss G = -0.33399534225463867 Unsupervised Loss C = 1.7621791362762451 Gradient Penalty = 0.0571829155087471\n",
      "Epoch 3: Supervised Loss = 2.2469396591186523 Unsupervised Loss G = -0.42549052834510803 Unsupervised Loss C = 1.8312703371047974 Gradient Penalty = 0.062440771609544754\n",
      "Epoch 4: Supervised Loss = 2.0880630016326904 Unsupervised Loss G = -0.5073314309120178 Unsupervised Loss C = 1.8447229862213135 Gradient Penalty = 0.061201538890600204\n",
      "Epoch 5: Supervised Loss = 2.0518534183502197 Unsupervised Loss G = -0.5680738091468811 Unsupervised Loss C = 1.8494975566864014 Gradient Penalty = 0.06240178272128105\n",
      "Epoch 6: Supervised Loss = 2.0354554653167725 Unsupervised Loss G = -0.5597502589225769 Unsupervised Loss C = 1.839065432548523 Gradient Penalty = 0.061295054852962494\n",
      "Epoch 7: Supervised Loss = 1.9411484003067017 Unsupervised Loss G = -0.5365355610847473 Unsupervised Loss C = 1.8301222324371338 Gradient Penalty = 0.060410454869270325\n",
      "Epoch 8: Supervised Loss = 1.9925578832626343 Unsupervised Loss G = -0.5469865798950195 Unsupervised Loss C = 1.81925368309021 Gradient Penalty = 0.06000298634171486\n",
      "Epoch 9: Supervised Loss = 1.8422900438308716 Unsupervised Loss G = -0.5388547778129578 Unsupervised Loss C = 1.8093152046203613 Gradient Penalty = 0.05958574265241623\n",
      "Epoch 10: Supervised Loss = 1.8786087036132812 Unsupervised Loss G = -0.5252838134765625 Unsupervised Loss C = 1.7955436706542969 Gradient Penalty = 0.05899916589260101\n",
      "Epoch 11: Supervised Loss = 1.8105307817459106 Unsupervised Loss G = -0.5156627297401428 Unsupervised Loss C = 1.7814759016036987 Gradient Penalty = 0.058041784912347794\n",
      "Epoch 12: Supervised Loss = 1.7162014245986938 Unsupervised Loss G = -0.5539822578430176 Unsupervised Loss C = 1.7685388326644897 Gradient Penalty = 0.05754629895091057\n",
      "Epoch 13: Supervised Loss = 1.6203275918960571 Unsupervised Loss G = -0.5441110134124756 Unsupervised Loss C = 1.7517974376678467 Gradient Penalty = 0.05663042142987251\n",
      "Epoch 14: Supervised Loss = 1.5783796310424805 Unsupervised Loss G = -0.5399497151374817 Unsupervised Loss C = 1.7386635541915894 Gradient Penalty = 0.055587612092494965\n",
      "Epoch 15: Supervised Loss = 1.4194021224975586 Unsupervised Loss G = -0.5537058115005493 Unsupervised Loss C = 1.7286670207977295 Gradient Penalty = 0.056036777794361115\n",
      "Epoch 16: Supervised Loss = 1.44228994846344 Unsupervised Loss G = -0.5268514156341553 Unsupervised Loss C = 1.7145615816116333 Gradient Penalty = 0.05422525852918625\n",
      "Epoch 17: Supervised Loss = 1.3717008829116821 Unsupervised Loss G = -0.5179867744445801 Unsupervised Loss C = 1.7074717283248901 Gradient Penalty = 0.05487914755940437\n",
      "Epoch 18: Supervised Loss = 1.2983527183532715 Unsupervised Loss G = -0.4710511267185211 Unsupervised Loss C = 1.693480134010315 Gradient Penalty = 0.05344768613576889\n",
      "Epoch 19: Supervised Loss = 1.2677628993988037 Unsupervised Loss G = -0.5038800239562988 Unsupervised Loss C = 1.6798694133758545 Gradient Penalty = 0.05248384550213814\n",
      "Epoch 20: Supervised Loss = 1.1330971717834473 Unsupervised Loss G = -0.5311957597732544 Unsupervised Loss C = 1.6710326671600342 Gradient Penalty = 0.05264708772301674\n",
      "Epoch 21: Supervised Loss = 1.106289029121399 Unsupervised Loss G = -0.5209787487983704 Unsupervised Loss C = 1.657486081123352 Gradient Penalty = 0.051658790558576584\n",
      "Epoch 22: Supervised Loss = 1.036374807357788 Unsupervised Loss G = -0.5266715288162231 Unsupervised Loss C = 1.6459890604019165 Gradient Penalty = 0.05196882411837578\n",
      "Epoch 23: Supervised Loss = 0.9030611515045166 Unsupervised Loss G = -0.49111804366111755 Unsupervised Loss C = 1.6278471946716309 Gradient Penalty = 0.050607144832611084\n",
      "Epoch 24: Supervised Loss = 0.9263496994972229 Unsupervised Loss G = -0.5301722288131714 Unsupervised Loss C = 1.618870496749878 Gradient Penalty = 0.0502503402531147\n",
      "Epoch 25: Supervised Loss = 0.8645932674407959 Unsupervised Loss G = -0.514461100101471 Unsupervised Loss C = 1.6037384271621704 Gradient Penalty = 0.049007438123226166\n",
      "Epoch 26: Supervised Loss = 0.7541962265968323 Unsupervised Loss G = -0.5196045637130737 Unsupervised Loss C = 1.5918527841567993 Gradient Penalty = 0.0488625206053257\n",
      "Epoch 27: Supervised Loss = 0.7667588591575623 Unsupervised Loss G = -0.5183824300765991 Unsupervised Loss C = 1.5764342546463013 Gradient Penalty = 0.0480431467294693\n",
      "Epoch 28: Supervised Loss = 0.7373682856559753 Unsupervised Loss G = -0.5062084197998047 Unsupervised Loss C = 1.5642902851104736 Gradient Penalty = 0.0476316399872303\n",
      "Epoch 29: Supervised Loss = 0.6727254986763 Unsupervised Loss G = -0.48595738410949707 Unsupervised Loss C = 1.547866940498352 Gradient Penalty = 0.0465739443898201\n",
      "Epoch 30: Supervised Loss = 0.6459680199623108 Unsupervised Loss G = -0.45553818345069885 Unsupervised Loss C = 1.532415509223938 Gradient Penalty = 0.04585481435060501\n",
      "Epoch 31: Supervised Loss = 0.5697507858276367 Unsupervised Loss G = -0.501900851726532 Unsupervised Loss C = 1.5184686183929443 Gradient Penalty = 0.04502858966588974\n",
      "Epoch 32: Supervised Loss = 0.5177590847015381 Unsupervised Loss G = -0.4780786335468292 Unsupervised Loss C = 1.500132441520691 Gradient Penalty = 0.044460393488407135\n",
      "Epoch 33: Supervised Loss = 0.5450775027275085 Unsupervised Loss G = -0.4648574888706207 Unsupervised Loss C = 1.4841444492340088 Gradient Penalty = 0.04354412481188774\n",
      "Epoch 34: Supervised Loss = 0.5334107279777527 Unsupervised Loss G = -0.44058164954185486 Unsupervised Loss C = 1.4666175842285156 Gradient Penalty = 0.042956653982400894\n",
      "Epoch 35: Supervised Loss = 0.4417882263660431 Unsupervised Loss G = -0.4529306888580322 Unsupervised Loss C = 1.4484003782272339 Gradient Penalty = 0.04327709600329399\n",
      "Epoch 36: Supervised Loss = 0.45498302578926086 Unsupervised Loss G = -0.35294434428215027 Unsupervised Loss C = 1.4281800985336304 Gradient Penalty = 0.041437406092882156\n",
      "Epoch 37: Supervised Loss = 0.4767289161682129 Unsupervised Loss G = -0.30010661482810974 Unsupervised Loss C = 1.4151170253753662 Gradient Penalty = 0.041482821106910706\n",
      "Epoch 38: Supervised Loss = 0.4036809504032135 Unsupervised Loss G = -0.30972468852996826 Unsupervised Loss C = 1.4014118909835815 Gradient Penalty = 0.04075002670288086\n",
      "Epoch 39: Supervised Loss = 0.3846125602722168 Unsupervised Loss G = -0.3268371522426605 Unsupervised Loss C = 1.3841572999954224 Gradient Penalty = 0.03921983018517494\n",
      "Epoch 40: Supervised Loss = 0.34700992703437805 Unsupervised Loss G = -0.3154720067977905 Unsupervised Loss C = 1.3641146421432495 Gradient Penalty = 0.03839889541268349\n",
      "Epoch 41: Supervised Loss = 0.32051774859428406 Unsupervised Loss G = -0.31582924723625183 Unsupervised Loss C = 1.340391993522644 Gradient Penalty = 0.037711724638938904\n",
      "Epoch 42: Supervised Loss = 0.314593106508255 Unsupervised Loss G = -0.2349943071603775 Unsupervised Loss C = 1.3205218315124512 Gradient Penalty = 0.036686234176158905\n",
      "Epoch 43: Supervised Loss = 0.30229759216308594 Unsupervised Loss G = -0.22547374665737152 Unsupervised Loss C = 1.2999933958053589 Gradient Penalty = 0.036046259105205536\n",
      "Epoch 44: Supervised Loss = 0.2840332090854645 Unsupervised Loss G = -0.1605638712644577 Unsupervised Loss C = 1.279455304145813 Gradient Penalty = 0.03508879616856575\n",
      "Epoch 45: Supervised Loss = 0.2693464159965515 Unsupervised Loss G = -0.14062543213367462 Unsupervised Loss C = 1.2604560852050781 Gradient Penalty = 0.03463403880596161\n",
      "Epoch 46: Supervised Loss = 0.28984078764915466 Unsupervised Loss G = -0.14892232418060303 Unsupervised Loss C = 1.2389991283416748 Gradient Penalty = 0.03364831581711769\n",
      "Epoch 47: Supervised Loss = 0.2775103449821472 Unsupervised Loss G = -0.15629111230373383 Unsupervised Loss C = 1.2205308675765991 Gradient Penalty = 0.03266279771924019\n",
      "Epoch 48: Supervised Loss = 0.2791859209537506 Unsupervised Loss G = -0.15806744992733002 Unsupervised Loss C = 1.2045730352401733 Gradient Penalty = 0.032888591289520264\n",
      "Epoch 49: Supervised Loss = 0.29825910925865173 Unsupervised Loss G = -0.1413886994123459 Unsupervised Loss C = 1.1802318096160889 Gradient Penalty = 0.031217217445373535\n",
      "---Finished Generative Training\n"
     ]
    }
   ],
   "source": [
    "# Run the evaluation\n",
    "evaluation_results, global_hyper_params = evaluate_full(\n",
    "    X_train, transformer, discrete_columns, latent_dims, hidden_dimensions, \n",
    "    parameters, hyper_params_sup, hyper_params_unsup, auto_epochs, gen_epochs,\n",
    "    key_sets, regressions, utility_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latent_dim</th>\n",
       "      <th>Decoded_ROC</th>\n",
       "      <th>ROC</th>\n",
       "      <th>CIO</th>\n",
       "      <th>pMSE</th>\n",
       "      <th>PMSE4</th>\n",
       "      <th>1-keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.341766</td>\n",
       "      <td>0.141999</td>\n",
       "      <td>0.117937</td>\n",
       "      <td>0.528250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.658826</td>\n",
       "      <td>0.331870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124532</td>\n",
       "      <td>0.501874</td>\n",
       "      <td>0.993289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.600167</td>\n",
       "      <td>0.571868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200512</td>\n",
       "      <td>0.197953</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.936614</td>\n",
       "      <td>0.863330</td>\n",
       "      <td>0.004997</td>\n",
       "      <td>0.157672</td>\n",
       "      <td>0.369312</td>\n",
       "      <td>0.993918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Latent_dim  Decoded_ROC       ROC       CIO      pMSE     PMSE4    1-keys\n",
       "0           0          NaN  0.341766  0.141999  0.117937  0.528250  0.000000\n",
       "1           1     0.658826  0.331870  0.000000  0.124532  0.501874  0.993289\n",
       "2           2     0.600167  0.571868  0.000000  0.200512  0.197953  0.000000\n",
       "3           3     0.936614  0.863330  0.004997  0.157672  0.369312  0.993918"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the lines\n",
    "plot_priv_utility(evaluation_results, False, '1-keys')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
