{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evanolsdal/Partial-Information-Tabular-GAN-PITGAN-/blob/main/colab_full_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijyn_6i8YZcs"
      },
      "source": [
        "First load in the github repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Zt9T4EtVoXU"
      },
      "outputs": [],
      "source": [
        "!git clone https://evanolsdal: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@github.com/evanolsdal/Partial-Information-Tabular-GAN-PITGAN-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4g8csCbW3hS"
      },
      "source": [
        "Load the cleaned census data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PUm5J-ZW1dK"
      },
      "outputs": [],
      "source": [
        "import pandas as  pd\n",
        "\n",
        "census = pd.read_csv('/content/Data/census_clean_subset_50000.csv', index_col=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vErUDt9Lb1Ei"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtNKd2rQWwla"
      },
      "outputs": [],
      "source": [
        "census.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0FdLUNRW7_6"
      },
      "source": [
        "Install the required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lehq2YjXyQ4"
      },
      "outputs": [],
      "source": [
        "# Move directories\n",
        "%cd /content/Partial-Information-Tabular-GAN-PITGAN-/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2EVvmI_JXGss"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYI2_qPJcMbM"
      },
      "source": [
        "Move to the code direcroty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YODsF6M6cPHv"
      },
      "outputs": [],
      "source": [
        "%cd /content/Partial-Information-Tabular-GAN-PITGAN-/Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16sPasBPVeaQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Models to be used\n",
        "from model.model_init import PITGAN\n",
        "from data_processing.data_transformer import DataTransformer\n",
        "\n",
        "# Data loading functions\n",
        "from data_processing.basic_synthetic_dataset import generate_basic_2D\n",
        "\n",
        "# Plot functions\n",
        "from visualizations.scatter_plots import plot_2D_data, plot_priv_utility\n",
        "from visualizations.training_loss_plots import plot_losses\n",
        "\n",
        "# Evaluation functinos\n",
        "from evaluation.privacy import compute_TCAP\n",
        "from evaluation.evaluation_procedure import evaluate_full, evaluate\n",
        "from evaluation.utility import compute_ROC, compute_CIO, compute_CIO_folds, compute_pMSE\n",
        "\n",
        "# Additional functions\n",
        "from model.model_helpers import get_latent_dims"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxo8uZoBVeaQ"
      },
      "source": [
        "This file contains the full streamlined evaluation procedure for any data.\n",
        "\n",
        "It follows the following steps\n",
        "1. It starts by loading in the data\n",
        "2. Then it fits a transformer to this data which is adequate\n",
        "3. Then full evaluation procedure is run over various latent dimensions\n",
        "4. Then these evaluation outputs are used to plot the privacy-utility graph\n",
        "5. Finally some of these optimal paramters from the evaluation are used to gain further insight into the model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXbju-_EVeaR"
      },
      "source": [
        "## 1) Load Data\n",
        "First the data is loaded in the data from whatever source. In this example the basic synthetic data example is used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKdGmIohVeaR"
      },
      "outputs": [],
      "source": [
        "# Specify the parameters to be used for the synthetic distribution\n",
        "# First we initialize the distribution for the basic example\n",
        "cats = [0.2, 0.5, 0.3]\n",
        "cat_names = ['small', 'medium', 'large']\n",
        "mu = [[0, 0], [2, 2.1], [4.5, 4.6]]\n",
        "sig = [\n",
        "    [[0.05, 0], [0, 0.02]],  # Mode1: Much narrower and taller\n",
        "    [[0.3, 0.15], [0.15, 0.3]],  # Mode2: Wider and more tilted\n",
        "    [[0.1, -0.08], [-0.08, 0.1]]  # Mode3: Moderate width but with a significant tilt in the opposite direction\n",
        "]\n",
        "\n",
        "# Load basic data\n",
        "X_plot = generate_basic_2D(cats, cat_names, mu, sig, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwCzNEaDVeaR"
      },
      "outputs": [],
      "source": [
        "# Plot the data to get a sense of the distribution\n",
        "plot_2D_data(X_plot, 'Basic Synthetic Data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XP6UlJHxVeaR"
      },
      "outputs": [],
      "source": [
        "# Get the train set\n",
        "X_train = generate_basic_2D(cats, cat_names, mu, sig, 1500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IbbdR3LVeaR"
      },
      "source": [
        "Another option is load in a subset of ACS census data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYSI59ZIVeaR"
      },
      "outputs": [],
      "source": [
        "# To be added\n",
        "X_train = census\n",
        "\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6KSUTYiVeaR"
      },
      "source": [
        "## 2) Fit Transformer\n",
        "\n",
        "This section fits the data transformer to the distribution. This is an important step of the process as the restructured representation can greatly impact the performace of the model.\n",
        "\n",
        "It is suggested to pick a representation which contains as few modes, or the most relevant modes, for the continuous variables as possible. This will both reduce the dimensionality of the feature space the generative model is trained on, as well as avoid unnecessarily complicated latice spaces that may either be difficult for the autoencoder to learn, or make the encoded space less useful later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA8KxGbJVeaR"
      },
      "outputs": [],
      "source": [
        "# Initialize the transformer\n",
        "transformer = DataTransformer()\n",
        "\n",
        "# Specify which columns are discrete, important for both the transformer and functions later on\n",
        "discrete_columns = ['REGION','SEX','MARST','RACE','CITIZEN','EDUC','HEALTHCOV','EMPSTAT','POVERTY']\n",
        "\n",
        "# Train the transformer\n",
        "transformer.fit(X_train, discrete_columns)\n",
        "\n",
        "# Get the dimensionality of the modes, repeat fitting until a sufficiently low numer of modes are found\n",
        "D_list, C_list = transformer.get_relevant_dimensions()\n",
        "\n",
        "C_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QorYs3D-VeaR"
      },
      "source": [
        "## 3) Run Evaluation\n",
        "\n",
        "This is the longest step, both to set up and to run. It consists of two steps, first setting up all of the parameters needed for the full evaluation procedure, then running the actual procedure.\n",
        "\n",
        "The first part is crucial for successful training. While grid search is employed in the evaluation procedure it, since this procedure is run for a number of different latent dimensions, the training time compounds the more parameters are added. It is recommended to run a handful of smaller scale tests to hone in on which parameter ranges would likely be the most appropriate. The individual parameter choices are explained in more detail below.\n",
        "\n",
        "The actual evaluation portion this is the part that will take the longest to run, so it is recommended to run on GPU supported processing for accelerated network training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkpcetbUVeaR"
      },
      "source": [
        "First take a look at the different options for the latent dimensions. The function latent_dims takes as input the total number of categories over all categorical variables, as well as the total number of modes across all continuous variables, and then outputs a table with the latent dimension size, the states on the lattice covered by this dimeniosn, and the number of states remaining.\n",
        "\n",
        "This function gives you an overall sense of how effective the different latent dimensions sizes may be, as well as the higher dimension size before identity mapping becomes possible. It is recommended to only run the evaluation on only the dimension lister here, or potentially less depending on prior knowledge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "oT-PSmwRVeaS"
      },
      "outputs": [],
      "source": [
        "# Run latent_dims\n",
        "get_latent_dims(D_list, C_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ct_dHA77VeaS"
      },
      "outputs": [],
      "source": [
        "# Select the dimensions for evaluation\n",
        "latent_dims = [0,5,10,15,20,25,30]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNffU3RzsWDe"
      },
      "source": [
        "# Preliminary Testing\n",
        "\n",
        "In this portion we just run some preliminary testing on the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQy3XWkoVeaS"
      },
      "source": [
        "The next portion specifies the size or complexity of the network, broken down into the size of the different network parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aCbFbK6VeaS"
      },
      "outputs": [],
      "source": [
        "# Initialize the dictionary for the model sizes\n",
        "hidden_dimensions = {\n",
        "    'dim_e': [256, 128, 64],\n",
        "    'dim_r': [64, 128, 256],\n",
        "    'dim_g': [512, 512, 512],\n",
        "    'dim_c': [512, 512, 512],\n",
        "}\n",
        "\n",
        "hidden_dimensions_small = {\n",
        "    'dim_e': [256, 128, 64],\n",
        "    'dim_r': [64, 128, 256],\n",
        "    'dim_g': [256, 256, 256],\n",
        "    'dim_c': [256, 256, 256],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9buSLIrVeaS"
      },
      "source": [
        "The next portion specifies the overall parameters to be used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4BWYe6rVeaS"
      },
      "outputs": [],
      "source": [
        "# Initialize the dictionary for the overall model parameters\n",
        "parameters = {\n",
        "    'alpha_sup': 1,\n",
        "    'alpha_grad': 10,\n",
        "    'batch_size': 1000,\n",
        "    'grad_step_critic': 0.001,\n",
        "    'grad_step_generator': 0.001,\n",
        "    'grad_step_autoencoding': 0.001,\n",
        "    'latent_sharpness': 25,\n",
        "    'critic_steps': 5,\n",
        "    'R': 25\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6F35hroNslS3"
      },
      "outputs": [],
      "source": [
        "model = PITGAN(0, hidden_dimensions_small, parameters, transformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "T52pxNWgCSPP"
      },
      "outputs": [],
      "source": [
        "model.get_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP5qZhlEtFgy"
      },
      "outputs": [],
      "source": [
        "losses_auto = model.fit_autoencoder(X_train, 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho5XEatPtO5E"
      },
      "outputs": [],
      "source": [
        "plot_losses(losses_auto, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c-XIudYgcy4"
      },
      "outputs": [],
      "source": [
        "losses_encoder = model.fit_encoder(X_train, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9YveKIzTEyZ"
      },
      "outputs": [],
      "source": [
        "decoded = model.get_decoded(X_train)\n",
        "\n",
        "ROC = compute_ROC(X_train, decoded, transformer)\n",
        "\n",
        "ROC['ROC'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BhU8c9iGR_fL"
      },
      "outputs": [],
      "source": [
        "from evaluation.privacy import compute_TCAP\n",
        "\n",
        "TCAP = compute_TCAP(X_train, X_train, [['REGION','SEX','MARST','RACE']], transformer, 0.95)\n",
        "\n",
        "TCAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRywUAgfgiPZ"
      },
      "outputs": [],
      "source": [
        "plot_losses(losses_encoder, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in80_EnBUYU0"
      },
      "outputs": [],
      "source": [
        "model.set_alpha_sup(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQSd75N2tS18"
      },
      "outputs": [],
      "source": [
        "losses_gen = model.fit_unsupervised(X_train, 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sR1B8I8bW1tx"
      },
      "outputs": [],
      "source": [
        "plot_losses(losses_gen, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSqXeVSFW38o"
      },
      "source": [
        "Intermediate evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "H_7cd4ZfW6JJ"
      },
      "outputs": [],
      "source": [
        "X_trans = transformer.transform(X_train)\n",
        "\n",
        "Y = model.get_latent(X_trans, True)\n",
        "\n",
        "Y = pd.DataFrame(Y)\n",
        "\n",
        "Y.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = losses_gen"
      ],
      "metadata": {
        "id": "1GXtVKuYrDFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in losses.keys():\n",
        "  losses[key].extend(losses_gen[key])"
      ],
      "metadata": {
        "id": "L38EQ5NF7paA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(losses, False)"
      ],
      "metadata": {
        "id": "HJXOqbte8MWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE0NqrZFt7AA"
      },
      "source": [
        "Then some preliminary evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amFwrUARt95p"
      },
      "outputs": [],
      "source": [
        "# Specify the sets of keys to be used for privacy evaluation\n",
        "key_sets = [['REGION','SEX'],['REGION','SEX','MARST','RACE']]\n",
        "\n",
        "# Specify the regressions to be sued for CIO evaluation\n",
        "regressions = {\n",
        "    'Income_Full': (['INCTOT'],['AGE'],['SEX','RACE','EDUC'])\n",
        "}\n",
        "\n",
        "# Specify utility weights\n",
        "util_weights = [0.33, 0.33, 0.33]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIsxGvCyeexA"
      },
      "outputs": [],
      "source": [
        "results = evaluate(X_train, model, transformer, discrete_columns, util_weights, key_sets, regressions)\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6Fnaz05lFuzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make cvs to output both\n",
        "#results_short.to_csv('/content/Data/results_short.csv')\n",
        "results.to_csv('/content/Data/results_long.csv')\n",
        "#results_latent_0.to_csv('/content/Data/results_latent_0.csv')"
      ],
      "metadata": {
        "id": "oTU4Ki-VDPbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6IGwnh0ssmg"
      },
      "source": [
        "# Full Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmbsqnKLVeaS"
      },
      "source": [
        "The next portion specifies the training specific hyper parameters to be used in the grid search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6INqcyCVeaS"
      },
      "outputs": [],
      "source": [
        "# Initialize the dict for the autoencoder hyperparameters\n",
        "hyper_params_sup = [0.001, 0.0005, 0.0001]\n",
        "\n",
        "# Initialize the dictionary for the generative model grid\n",
        "hyper_params_unsup = {\n",
        "    'grad_step_critic': [0.001, 0.0001],\n",
        "    'grad_step_generator': [0.001, 0.0001]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtHXnCl7VeaS"
      },
      "outputs": [],
      "source": [
        "# Initialize the dict for the autoencoder hyperparameters\n",
        "hyper_params_sup = [0.001, 0.0001]\n",
        "\n",
        "# Initialize the dictionary for the generative model grid\n",
        "hyper_params_unsup = {\n",
        "    'grad_step_critic': [0.001],\n",
        "    'grad_step_generator': [0.0001]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvmmabM1VeaS"
      },
      "source": [
        "The next portion specifies the number of ephods for the autoencoder and unsupervised trianing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q_wOPEXVeaS"
      },
      "outputs": [],
      "source": [
        "# Specify autoencoder epochs\n",
        "auto_epochs = 100\n",
        "\n",
        "# Specify unsupervised epochs\n",
        "gen_epochs = 350"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2outkGBVeaS"
      },
      "outputs": [],
      "source": [
        "# Specify autoencoder epochs\n",
        "auto_epochs = 100\n",
        "\n",
        "# Specify unsupervised epochs\n",
        "gen_epochs = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpSfFxfRVeaS"
      },
      "source": [
        "Next section specifies the evaluation parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef5s7SVnVeaS"
      },
      "outputs": [],
      "source": [
        "# Specify the sets of keys to be used for privacy evaluation\n",
        "key_sets = [['REGION','SEX'],['REGION','SEX','MARST','RACE']]\n",
        "\n",
        "# Specify the regressions to be sued for CIO evaluation\n",
        "regressions = {\n",
        "    'Income_Full': (['INCTOT'],['AGE','FAMSIZE'],['SEX','RACE','CITIZEN','EDUC'])\n",
        "}\n",
        "\n",
        "# Specify utility weights\n",
        "utility_weights = [0.33, 0.33, 0.33]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPyV4I4nVeaS"
      },
      "source": [
        "Finally run the actual evaluation procedure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "T1SGgaRaVeaS"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation\n",
        "evaluation_results, global_hyper_params = evaluate_full(\n",
        "    X_train, transformer, discrete_columns, latent_dims, hidden_dimensions,\n",
        "    parameters, hyper_params_sup, hyper_params_unsup, auto_epochs, gen_epochs,\n",
        "    key_sets, regressions, utility_weights\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaTVjuGNVeaS"
      },
      "outputs": [],
      "source": [
        "evaluation_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3R8yVQnnVeaS"
      },
      "outputs": [],
      "source": [
        "# Plot the lines\n",
        "plot_priv_utility(evaluation_results, False, '1-keys')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RxBr3ikiCo6"
      },
      "outputs": [],
      "source": [
        "result_0_short_25_1 = {\n",
        "    'Latent_dim': 0,\n",
        "    'Decoded_ROC': 0.16182,\n",
        "    'ROC': 0.825212,\n",
        "    'CIO': 0.019965,\n",
        "    'pMSE': 0.190559,\n",
        "    'PMSE4': 0.237765,\n",
        "    'Utility': 0.357371,\n",
        "    '2-keys_TCAP': 0.18387,\n",
        "    '2-keys_TCAP_raw': 3739.626835,\n",
        "    '2-keys_TCAP_real': 0.18376,\n",
        "    '2-keys_TCAP_raw_real': 2628.570091,\n",
        "    '4-keys_TCAP': 0.62579,\n",
        "    '4-keys_TCAP_raw': 8583.451884,\n",
        "    '4-keys_TCAP_real': 0.656797,\n",
        "    '4-keys_TCAP_raw_real': 7814.707986\n",
        "}\n",
        "\n",
        "# Ignore\n",
        "result_0_short_25 = {\n",
        "    'Latent_dim': 0,\n",
        "    'Decoded_ROC': 0.16182,\n",
        "    'ROC': 0.837749,\n",
        "    'CIO': 0.023547,\n",
        "    'pMSE': 0.184174,\n",
        "    'PMSE4': 0.263304,\n",
        "    'Utility': 0.367478,\n",
        "    '2-keys_TCAP': 0.274305,\n",
        "    '2-keys_TCAP_raw': 2219.670663,\n",
        "    '2-keys_TCAP_real': 0.274539,\n",
        "    '2-keys_TCAP_raw_real': 2628.570091,\n",
        "    '4-keys_TCAP': 0.665363,\n",
        "    '4-keys_TCAP_raw': 8475.822601,\n",
        "    '4-keys_TCAP_real': 0.681405,\n",
        "    '4-keys_TCAP_raw_real': 7858.332723\n",
        "}\n",
        "\n",
        "result_40_short_25 = {\n",
        "    'Latent_dim': 40,\n",
        "    'Decoded_ROC': 0.928586,\n",
        "    'ROC': 0.878069,\n",
        "    'CIO': 0.260674,\n",
        "    'pMSE': 0.164897,\n",
        "    'PMSE4': 0.340412,\n",
        "    'Utility': 0.563672,\n",
        "    '2-keys_TCAP': 0.095643,\n",
        "    '2-keys_TCAP_raw': 4082.884389,\n",
        "    '2-keys_TCAP_real': 0.095649,\n",
        "    '2-keys_TCAP_raw_real': 4044.503912,\n",
        "    '4-keys_TCAP': 0.563672,\n",
        "    '4-keys_TCAP_raw': 8263.182978,\n",
        "    '4-keys_TCAP_real': 0.637599,\n",
        "    '4-keys_TCAP_raw_real': 8174.90914\n",
        "}\n",
        "\n",
        "result_35_short_25 = {\n",
        "    'Latent_dim': 35,\n",
        "    'Decoded_ROC': 0.910972,\n",
        "    'ROC': 0.868917,\n",
        "    'CIO': 0.337614,\n",
        "    'pMSE': 0.165848,\n",
        "    'PMSE4': 0.336608,\n",
        "    'Utility': 0.509236,\n",
        "    '2-keys_TCAP': 0.09642,\n",
        "    '2-keys_TCAP_raw': 2577.197649,\n",
        "    '2-keys_TCAP_real': 0.096469,\n",
        "    '2-keys_TCAP_raw_real': 2721.76736,\n",
        "    '4-keys_TCAP': 0.546491,\n",
        "    '4-keys_TCAP_raw': 7368.56122,\n",
        "    '4-keys_TCAP_real': 0.574245,\n",
        "    '4-keys_TCAP_raw_real': 7176.566336\n",
        "}\n",
        "\n",
        "result_30_short_25 = {\n",
        "    'Latent_dim': 30,\n",
        "    'Decoded_ROC': 0.86663,\n",
        "    'ROC': 0.883025,\n",
        "    'CIO': 0.323324,\n",
        "    'pMSE': 0.172332,\n",
        "    'PMSE4': 0.310673,\n",
        "    'Utility': 0.500617,\n",
        "    '2-keys_TCAP': 0.095989,\n",
        "    '2-keys_TCAP_raw': 3506.010523,\n",
        "    '2-keys_TCAP_real': 0.095997,\n",
        "    '2-keys_TCAP_raw_real': 3538.176639,\n",
        "    '4-keys_TCAP': 0.635361,\n",
        "    '4-keys_TCAP_raw': 8560.724106,\n",
        "    '4-keys_TCAP_real': 0.697561,\n",
        "    '4-keys_TCAP_raw_real': 8384.150991\n",
        "}\n",
        "\n",
        "result_25_short_25 = {\n",
        "    'Latent_dim': 25\t,\n",
        "    'Decoded_ROC': 0.814107,\n",
        "    'ROC': 0.879979,\n",
        "    'CIO': 0.192239,\n",
        "    'pMSE': 0.178593,\n",
        "    'PMSE4': 0.285629,\n",
        "    'Utility': 0.448089,\n",
        "    '2-keys_TCAP': 0.095918,\n",
        "    '2-keys_TCAP_raw': 2247.357244,\n",
        "    '2-keys_TCAP_real': 0.096057,\n",
        "    '2-keys_TCAP_raw_real': 2273.086111,\n",
        "    '4-keys_TCAP': 0.614647,\n",
        "    '4-keys_TCAP_raw': 7390.24296,\n",
        "    '4-keys_TCAP_real': 0.663988,\n",
        "    '4-keys_TCAP_raw_real': 7181.640335\n",
        "}\n",
        "\n",
        "\n",
        "result_20_short_25 = {\n",
        "    'Latent_dim': 20,\n",
        "    'Decoded_ROC': 0.770505,\n",
        "    'ROC': 0.878192,\n",
        "    'CIO': 0.250031,\n",
        "    'pMSE': 0.193494,\n",
        "    'PMSE4': 0.226023,\n",
        "    'Utility': 0.446901,\n",
        "    '2-keys_TCAP': 0.096026,\n",
        "    '2-keys_TCAP_raw': 2951.848705,\n",
        "    '2-keys_TCAP_real': 0.096102,\n",
        "    '2-keys_TCAP_raw_real': 2836.261928,\n",
        "    '4-keys_TCAP': 0.616756,\n",
        "    '4-keys_TCAP_raw': 8199.357299,\n",
        "    '4-keys_TCAP_real': 0.671322,\n",
        "    '4-keys_TCAP_raw_real': 8017.448205\n",
        "}\n",
        "\n",
        "result_15_short_25 = {\n",
        "    'Latent_dim': 15,\n",
        "    'Decoded_ROC': 0.790159,\n",
        "    'ROC': 0.869095,\n",
        "    'CIO': 0.074362,\n",
        "    'pMSE': 0.207727,\n",
        "    'PMSE4': 0.169094,\n",
        "    'Utility': 0.367142,\n",
        "    '2-keys_TCAP': 0.096479,\n",
        "    '2-keys_TCAP_raw': 1932.855006,\n",
        "    '2-keys_TCAP_real': 0.096484,\n",
        "    '2-keys_TCAP_raw_real': 1820.841943,\n",
        "    '4-keys_TCAP': 0.592277,\n",
        "    '4-keys_TCAP_raw': 6966.932778,\n",
        "    '4-keys_TCAP_real': 0.62371,\n",
        "    '4-keys_TCAP_raw_real': 7028.563579\n",
        "}\n",
        "\n",
        "result_5_short_25_2 = {\n",
        "    'Latent_dim': 5,\n",
        "    'Decoded_ROC': 0.577255,\n",
        "    'ROC': 0.837749,\n",
        "    'CIO': 0.086042,\n",
        "    'pMSE': 0.191918,\n",
        "    'PMSE4': 0.232327,\n",
        "    'Utility': 0.381519,\n",
        "    '2-keys_TCAP': 0.273863,\n",
        "    '2-keys_TCAP_raw': 3533.386992,\n",
        "    '2-keys_TCAP_real': 0.274015,\n",
        "    '2-keys_TCAP_raw_real': 3525.590375,\n",
        "    '4-keys_TCAP': 0.606629,\n",
        "    '4-keys_TCAP_raw': 9233.851073,\n",
        "    '4-keys_TCAP_real': 0.631479,\n",
        "    '4-keys_TCAP_raw_real': 8874.891596\n",
        "}\n",
        "\n",
        "result_10_short_25 = {\n",
        "    'Latent_dim': 10,\n",
        "    'Decoded_ROC': 0.664653,\n",
        "    'ROC': 0.845414,\n",
        "    'CIO': 0.078342,\n",
        "    'pMSE': 0.193459,\n",
        "    'PMSE4': 0.247674,\n",
        "    'Utility': 0.390476,\n",
        "    '2-keys_TCAP': 0.185601,\n",
        "    '2-keys_TCAP_raw': 4897.647931,\n",
        "    '2-keys_TCAP_real': 0.185646,\n",
        "    '2-keys_TCAP_raw_real': 4795.912707,\n",
        "    '4-keys_TCAP': 0.57735,\n",
        "    '4-keys_TCAP_raw': 9561.700567,\n",
        "    '4-keys_TCAP_real': 0.614126,\n",
        "    '4-keys_TCAP_raw_real': 9096.567186\n",
        "}\n",
        "\n",
        "result_5_short_25 = {\n",
        "    'Latent_dim': 5,\n",
        "    'Decoded_ROC': 0.577255,\n",
        "    'ROC': 0.822178,\n",
        "    'CIO': 0.222227,\n",
        "    'pMSE': 0.190233,\n",
        "    'PMSE4': 0.23907,\n",
        "    'Utility': 0.423547,\n",
        "    '2-keys_TCAP': 0.267189,\n",
        "    '2-keys_TCAP_raw': 4359.920181,\n",
        "    '2-keys_TCAP_real': 0.267022,\n",
        "    '2-keys_TCAP_raw_real': 4482.67778,\n",
        "    '4-keys_TCAP': 0.61942,\n",
        "    '4-keys_TCAP_raw': 8384.596653,\n",
        "    '4-keys_TCAP_real': 0.636558,\n",
        "    '4-keys_TCAP_raw_real': 8093.791675\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "511RNJwcQfeU"
      },
      "outputs": [],
      "source": [
        "result_0_long_100_new = {\n",
        "    'Latent_dim': 0,\n",
        "    'Decoded_ROC': 0.16182,\n",
        "    'ROC': 0.886575,\n",
        "    'CIO': 0.093491,\n",
        "    'pMSE': 0.161492,\n",
        "    'PMSE4': 0.354033,\n",
        "    'Utility': 0.440252,\n",
        "    '2-keys_TCAP': 0.096525,\n",
        "    '2-keys_TCAP_raw': 2719.024154,\n",
        "    '2-keys_TCAP_real': 0.096469,\n",
        "    '2-keys_TCAP_raw_real': 2721.76736,\n",
        "    '4-keys_TCAP': 0.568859,\n",
        "    '4-keys_TCAP_raw': 8664.533789,\n",
        "    '4-keys_TCAP_real': 0.611516,\n",
        "    '4-keys_TCAP_raw_real': 8419.939252\n",
        "}\n",
        "\n",
        "result_0_long_75_new = {\n",
        "    'Latent_dim': 0,\n",
        "    'Decoded_ROC': 0.16182,\n",
        "    'ROC': 0.913244,\n",
        "    'CIO': 0.086184,\n",
        "    'pMSE': 0.163352,\n",
        "    'PMSE4': 0.346591,\n",
        "    'Utility': 0.447486,\n",
        "    '2-keys_TCAP': 0.096241,\n",
        "    '2-keys_TCAP_raw': 2511.703994,\n",
        "    '2-keys_TCAP_real': 0.096306,\n",
        "    '2-keys_TCAP_raw_real': 2727.203848,\n",
        "    '4-keys_TCAP': 0.611411,\n",
        "    '4-keys_TCAP_raw': 8335.523284,\n",
        "    '4-keys_TCAP_real': 0.635125,\n",
        "    '4-keys_TCAP_raw_real': 8158.947179\n",
        "}\n",
        "\n",
        "result_0_long_50_new = {\n",
        "    'Latent_dim': 0,\n",
        "    'Decoded_ROC': 0.16182,\n",
        "    'ROC': 0.826037,\n",
        "    'CIO': 0.040566,\n",
        "    'pMSE': 0.176858,\n",
        "    'PMSE4': 0.292569,\n",
        "    'Utility': 0.382527,\n",
        "    '2-keys_TCAP': 0.184485,\n",
        "    '2-keys_TCAP_raw': 4748.460119,\n",
        "    '2-keys_TCAP_real': 0.184427,\n",
        "    '2-keys_TCAP_raw_real': 4465.225549,\n",
        "    '4-keys_TCAP': 0.63872,\n",
        "    '4-keys_TCAP_raw': 9125.990179,\n",
        "    '4-keys_TCAP_real': 0.644706,\n",
        "    '4-keys_TCAP_raw_real': 8561.472775\n",
        "}\n",
        "\n",
        "# Ignore\n",
        "result_0_long_50 = {\n",
        "    'Latent_dim': 0,\n",
        "    'Decoded_ROC': 0.16182,\n",
        "    'ROC': 0.840895,\n",
        "    'CIO': 0.011487,\n",
        "    'pMSE': 0.170007,\n",
        "    'PMSE4': 0.319972,\n",
        "    'Utility': 0.386877,\n",
        "    '2-keys_TCAP': 0.18588,\n",
        "    '2-keys_TCAP_raw': 4245.559094,\n",
        "    '2-keys_TCAP_real': 0.185849,\n",
        "    '2-keys_TCAP_raw_real': 4125.253025,\n",
        "    '4-keys_TCAP': 0.625459,\n",
        "    '4-keys_TCAP_raw': 9293.918469,\n",
        "    '4-keys_TCAP_real': 0.617956,\n",
        "    '4-keys_TCAP_raw_real': 8636.440269\n",
        "}\n",
        "\n",
        "result_40_long_50 = {\n",
        "    'Latent_dim': 40,\n",
        "    'Decoded_ROC': 0.928586,\n",
        "    'ROC': 0.918597,\n",
        "    'CIO': 0.600014,\n",
        "    'pMSE': 0.157952,\n",
        "    'PMSE4': 0.368192,\n",
        "    'Utility': 0.622645,\n",
        "    '2-keys_TCAP': 0.096468,\n",
        "    '2-keys_TCAP_raw': 2737.570116,\n",
        "    '2-keys_TCAP_real': 0.096469,\n",
        "    '2-keys_TCAP_raw_real': 2721.76736,\n",
        "    '4-keys_TCAP': 0.67926,\n",
        "    '4-keys_TCAP_raw': 8224.266971,\n",
        "    '4-keys_TCAP_real': 0.791777,\n",
        "    '4-keys_TCAP_raw_real': 8209.680645\n",
        "}\n",
        "\n",
        "result_35_long_50 = {\n",
        "    'Latent_dim': 35,\n",
        "    'Decoded_ROC': 0.910972,\n",
        "    'ROC': 0.920398,\n",
        "    'CIO': 0.482534,\n",
        "    'pMSE': 0.164431,\n",
        "    'PMSE4': 0.342277,\n",
        "    'Utility': 0.575919,\n",
        "    '2-keys_TCAP': 0.096056,\n",
        "    '2-keys_TCAP_raw': 3117.099052,\n",
        "    '2-keys_TCAP_real': 0.096136,\n",
        "    '2-keys_TCAP_raw_real': 3146.343934,\n",
        "    '4-keys_TCAP': 0.600394,\n",
        "    '4-keys_TCAP_raw': 8353.830971,\n",
        "    '4-keys_TCAP_real': 0.628693,\n",
        "    '4-keys_TCAP_raw_real': 8262.50675\n",
        "}\n",
        "\n",
        "result_30_long_50 = {\n",
        "    'Latent_dim': 30,\n",
        "    'Decoded_ROC': 0.86663,\n",
        "    'ROC': 0.939677,\n",
        "    'CIO': 0.444881,\n",
        "    'pMSE': 0.167515,\n",
        "    'PMSE4': 0.32994,\n",
        "    'Utility': 0.565784,\n",
        "    '2-keys_TCAP': 0.097129,\n",
        "    '2-keys_TCAP_raw': 1912.379298,\n",
        "    '2-keys_TCAP_real': 0.097118,\n",
        "    '2-keys_TCAP_raw_real': 1910.794569,\n",
        "    '4-keys_TCAP': 0.657577,\n",
        "    '4-keys_TCAP_raw': 8035.061166,\n",
        "    '4-keys_TCAP_real': 0.700745,\n",
        "    '4-keys_TCAP_raw_real': 7963.762885\n",
        "}\n",
        "\n",
        "result_25_long_50 = {\n",
        "    'Latent_dim': 25,\n",
        "    'Decoded_ROC': 0.814107,\n",
        "    'ROC': 0.947054,\n",
        "    'CIO': 0.476691,\n",
        "    'pMSE': 0.177695,\n",
        "    'PMSE4': 0.28922,\n",
        "    'Utility': 0.565279,\n",
        "    '2-keys_TCAP': 0.096747,\n",
        "    '2-keys_TCAP_raw': 2282.554654,\n",
        "    '2-keys_TCAP_real': 0.096738,\n",
        "    '2-keys_TCAP_raw_real': 2329.934655,\n",
        "    '4-keys_TCAP': 0.607043,\n",
        "    '4-keys_TCAP_raw': 7166.780116,\n",
        "    '4-keys_TCAP_real': 0.674637,\n",
        "    '4-keys_TCAP_raw_real': 7275.084304\n",
        "}\n",
        "\n",
        "result_20_long_50 = {\n",
        "    'Latent_dim': 20,\n",
        "    'Decoded_ROC': 0.770505,\n",
        "    'ROC': 0.937358,\n",
        "    'CIO': 0.238819,\n",
        "    'pMSE': 0.18549,\n",
        "    'PMSE4': 0.258038,\n",
        "    'Utility': 0.470651,\n",
        "    '2-keys_TCAP': 0.096954,\n",
        "    '2-keys_TCAP_raw': 1574.538156,\n",
        "    '2-keys_TCAP_real': 0.096976,\n",
        "    '2-keys_TCAP_raw_real': 1456.676832,\n",
        "    '4-keys_TCAP': 0.568634,\n",
        "    '4-keys_TCAP_raw': 7168.149863,\n",
        "    '4-keys_TCAP_real': 0.645868,\n",
        "    '4-keys_TCAP_raw_real': 7100.464623\n",
        "}\n",
        "\n",
        "result_15_long_50 = {\n",
        "    'Latent_dim': 15,\n",
        "    'Decoded_ROC': 0.790159,\n",
        "    'ROC': 0.937823,\n",
        "    'CIO': 0.292066,\n",
        "    'pMSE': 0.191064,\n",
        "    'PMSE4': 0.33439,\n",
        "    'Utility': 0.468915,\n",
        "    '2-keys_TCAP': 0.096723,\n",
        "    '2-keys_TCAP_raw': 2342.236547,\n",
        "    '2-keys_TCAP_real': 0.096738,\n",
        "    '2-keys_TCAP_raw_real': 2329.934655,\n",
        "    '4-keys_TCAP': 0.656197,\n",
        "    '4-keys_TCAP_raw': 7671.794865,\n",
        "    '4-keys_TCAP_real': 0.690426,\n",
        "    '4-keys_TCAP_raw_real': 7689.066113\n",
        "}\n",
        "\n",
        "result_10_long_50 = {\n",
        "    'Latent_dim': 10,\n",
        "    'Decoded_ROC': 0.664653,\n",
        "    'ROC': 0.888419,\n",
        "    'CIO': 0.166939,\n",
        "    'pMSE': 0.166403,\n",
        "    'PMSE4': 0.33439,\n",
        "    'Utility': 0.458617,\n",
        "    '2-keys_TCAP': 0.096076,\n",
        "    '2-keys_TCAP_raw': 2167.387764,\n",
        "    '2-keys_TCAP_real': 0.096057,\n",
        "    '2-keys_TCAP_raw_real': 2273.086111,\n",
        "    '4-keys_TCAP': 0.620384,\n",
        "    '4-keys_TCAP_raw': 6916.23497,\n",
        "    '4-keys_TCAP_real': 0.662705,\n",
        "    '4-keys_TCAP_raw_real': 7160.464754\n",
        "}\n",
        "\n",
        "result_5_long_50 = {\n",
        "    'Latent_dim': 5,\n",
        "    'Decoded_ROC': 0.572597,\n",
        "    'ROC': 0.88443,\n",
        "    'CIO': 0.051291,\n",
        "    'pMSE': 0.166067,\n",
        "    'PMSE4': 0.335733,\n",
        "    'Utility': 0.41958,\n",
        "    '2-keys_TCAP': 0.096853,\n",
        "    '2-keys_TCAP_raw': 2272.64798,\n",
        "    '2-keys_TCAP_real': 0.096738,\n",
        "    '2-keys_TCAP_raw_real': 2329.934655,\n",
        "    '4-keys_TCAP': 0.621932,\n",
        "    '4-keys_TCAP_raw': 8177.64564,\n",
        "    '4-keys_TCAP_real': 0.640641,\n",
        "    '4-keys_TCAP_raw_real': 7954.23636\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}